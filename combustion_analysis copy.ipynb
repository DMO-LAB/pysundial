{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f5926e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rk_solver_cpp\n",
    "from scipy.integrate import ode\n",
    "import SundialsPy as SP\n",
    "import numpy as np\n",
    "import cantera as ct\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from typing import Tuple, List, Dict, Any, Optional\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d93b15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel = 'nc12h26:1.0'\n",
    "oxidizer = 'N2:3.76, O2:1.0'\n",
    "fuel_species = 'nc12h26'\n",
    "mechanism_file = '/Users/elotech/Downloads/research_code/large_mechanism/n-dodecane.yaml'\n",
    "rtol = 1e-6\n",
    "atol = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ec2f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ODE SYSTEM DEFINITION\n",
    "# ============================================================================\n",
    "\n",
    "def combustion_rhs(t: float, y: np.ndarray, gas: ct.Solution, pressure: float) -> np.ndarray:\n",
    "    \"\"\"Right-hand side of the combustion ODE system.\n",
    "    \n",
    "    Args:\n",
    "        t: Current time\n",
    "        y: Current state vector [T, Y1, Y2, ...]\n",
    "        gas: Cantera gas object\n",
    "        pressure: Constant pressure\n",
    "    \n",
    "    Returns:\n",
    "        dydt: Time derivatives [dT/dt, dY1/dt, dY2/dt, ...]\n",
    "    \"\"\"\n",
    "    # Extract temperature and mass fractions\n",
    "    T = y[0]\n",
    "    Y = y[1:]\n",
    "    \n",
    "    # Update the gas state\n",
    "    gas.TPY = T, pressure, Y\n",
    "    \n",
    "    # Get thermodynamic properties\n",
    "    rho = gas.density_mass\n",
    "    wdot = gas.net_production_rates\n",
    "    cp = gas.cp_mass\n",
    "    h = gas.partial_molar_enthalpies\n",
    "    \n",
    "    # Calculate temperature derivative (energy equation)\n",
    "    dTdt = -(np.dot(h, wdot) / (rho * cp))\n",
    "    \n",
    "    # Calculate species derivatives (mass conservation)\n",
    "    dYdt = wdot * gas.molecular_weights / rho\n",
    "    \n",
    "    # Combine into full derivative vector\n",
    "    return np.hstack([dTdt, dYdt])\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SOLVER CREATION FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def create_sundials_solver(method: str, y: np.ndarray, t: float, system_size: int, rtol: float, atol: np.ndarray, \n",
    "                          gas: ct.Solution, pressure: float, table_id: Optional[SP.arkode.ButcherTable] = None) -> Any:\n",
    "    \"\"\"Create a SUNDIALS solver.\n",
    "    \n",
    "    Args:\n",
    "        method: Solver method ('cvode_bdf', 'cvode_adams', 'arkode_erk')\n",
    "        system_size: Size of the ODE system\n",
    "        rtol: Relative tolerance\n",
    "        atol: Absolute tolerance array\n",
    "        gas: Cantera gas object\n",
    "        pressure: Constant pressure\n",
    "    \n",
    "    Returns:\n",
    "        solver: Initialized SUNDIALS solver\n",
    "    \"\"\"\n",
    "    if method == 'cvode_bdf':\n",
    "        solver = SP.cvode.CVodeSolver(\n",
    "            system_size=system_size,\n",
    "            rhs_fn=lambda t, y: combustion_rhs(t, y, gas, pressure),\n",
    "            iter_type=SP.cvode.IterationType.NEWTON\n",
    "        )\n",
    "    elif method == 'cvode_adams':\n",
    "        solver = SP.cvode.CVodeSolver(\n",
    "            system_size=system_size,\n",
    "            rhs_fn=lambda t, y: combustion_rhs(t, y, gas, pressure),\n",
    "            iter_type=SP.cvode.IterationType.FUNCTIONAL\n",
    "        )\n",
    "    elif method == 'arkode_erk':\n",
    "        solver = SP.arkode.ARKodeSolver(\n",
    "            system_size=system_size,\n",
    "            explicit_fn=lambda t, y: combustion_rhs(t, y, gas, pressure),\n",
    "            implicit_fn=None,\n",
    "            butcher_table=SP.arkode.ButcherTable.ARK548L2SA_ERK_8_4_5 if table_id is None else table_id\n",
    "        )\n",
    "    elif method == 'arkode_dirk':\n",
    "        solver = SP.arkode.ARKodeSolver(\n",
    "            system_size=system_size,\n",
    "            explicit_fn=lambda t, y: combustion_rhs(t, y, gas, pressure),\n",
    "            implicit_fn=lambda t, y: combustion_rhs(t, y, gas, pressure),\n",
    "            butcher_table=SP.arkode.ButcherTable.SDIRK_2_1_2 if table_id is None else table_id,\n",
    "            linsol_type=SP.cvode.LinearSolverType.DENSE\n",
    "        )\n",
    "        solver._py_explicit = lambda t, y: combustion_rhs(t, y, gas, pressure)\n",
    "        solver._py_implicit = lambda t, y: combustion_rhs(t, y, gas, pressure)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown SUNDIALS method: {method}\")\n",
    "    \n",
    "    solver.initialize(y, t, rtol, atol)\n",
    "    return solver\n",
    "\n",
    "def create_cpp_solver(method: str, t: float, y: np.ndarray, t_end: float, \n",
    "                     rtol: float, atol: float, gas: ct.Solution, pressure: float) -> Any:\n",
    "    \"\"\"Create a C++ RK solver.\n",
    "    \n",
    "    Args:\n",
    "        method: Solver method ('cpp_rk23', 'cpp_rk45', etc.)\n",
    "        t: Current time\n",
    "        y: Current state\n",
    "        t_end: End time\n",
    "        rtol: Relative tolerance\n",
    "        atol: Absolute tolerance\n",
    "        gas: Cantera gas object\n",
    "        pressure: Constant pressure\n",
    "    \n",
    "    Returns:\n",
    "        solver: Initialized C++ solver\n",
    "    \"\"\"\n",
    "    if method == 'cpp_rk23':\n",
    "        return rk_solver_cpp.RK23(\n",
    "            lambda t, y: combustion_rhs(t, y, gas, pressure), \n",
    "            float(t), np.array(y), float(t_end), rtol=rtol, atol=atol\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown C++ method: {method}\")\n",
    "\n",
    "def create_scipy_solver(method: str, t: float, y: np.ndarray, rtol: float, atol: float,\n",
    "                       gas: ct.Solution, pressure: float) -> Any:\n",
    "    \"\"\"Create a SciPy solver.\n",
    "    \n",
    "    Args:\n",
    "        method: Solver method ('scipy_rk23', 'scipy_bdf', etc.)\n",
    "        t: Current time\n",
    "        y: Current state\n",
    "        rtol: Relative tolerance\n",
    "        atol: Absolute tolerance\n",
    "        gas: Cantera gas object\n",
    "        pressure: Constant pressure\n",
    "    \n",
    "    Returns:\n",
    "        solver: Initialized SciPy solver\n",
    "    \"\"\"\n",
    "    method_parts = method.split('_')\n",
    "    if len(method_parts) != 3:\n",
    "        raise ValueError(f\"Invalid SciPy method format: {method}\")\n",
    "    \n",
    "    solver_type, method_name = method_parts[1], method_parts[2]\n",
    "    solver = ode(lambda t, y: combustion_rhs(t, y, gas, pressure)).set_integrator(\n",
    "        solver_type, method=method_name, rtol=rtol, atol=atol, nsteps=10000\n",
    "    )\n",
    "    solver.set_initial_value(y, t)\n",
    "    return solver\n",
    "\n",
    "def create_solver(method: str, gas: ct.Solution, y: np.ndarray, t: float, \n",
    "                 rtol: float, atol: float, t_end: Optional[float] = None, pressure: float = ct.one_atm, table_id: Optional[SP.arkode.ButcherTable] = None) -> Any:\n",
    "    \"\"\"Create the appropriate solver based on method.\n",
    "    \n",
    "    Args:\n",
    "        method: Solver method string\n",
    "        gas: Cantera gas object\n",
    "        y: Current state\n",
    "        t: Current time\n",
    "        rtol: Relative tolerance\n",
    "        atol: Absolute tolerance\n",
    "        t_end: End time (for some solvers)\n",
    "    \n",
    "    Returns:\n",
    "        solver: Initialized solver\n",
    "    \"\"\"\n",
    "    system_size = 1 + gas.n_species\n",
    "    \n",
    "    # Create absolute tolerance array\n",
    "    if np.isscalar(atol):\n",
    "        abs_tol = np.ones(system_size) * atol\n",
    "    else:\n",
    "        abs_tol = np.asarray(atol)\n",
    "        if len(abs_tol) == 1:\n",
    "            abs_tol = np.ones(system_size) * abs_tol[0]\n",
    "    \n",
    "    if method.startswith('cvode_') or method.startswith('arkode_'):\n",
    "        return create_sundials_solver(method, y, t, system_size, rtol, abs_tol, gas, pressure, table_id)\n",
    "    elif method.startswith('cpp_'):\n",
    "        return create_cpp_solver(method, t, y, t_end, rtol, atol, gas, pressure)\n",
    "    elif method.startswith('scipy_'):\n",
    "        return create_scipy_solver(method, t, y, rtol, atol, gas, pressure)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown solver method: {method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d98d330",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# INTEGRATION FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def integrate_single_step(method: str, gas: ct.Solution, y: np.ndarray, t: float, \n",
    "                         timestep: float, rtol: float, atol: float, fuel: str, pressure: float=ct.one_atm, table_id: Optional[SP.arkode.ButcherTable] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Integrate one step with the specified method.\n",
    "    \n",
    "    Args:\n",
    "        method: Solver method\n",
    "        gas: Cantera gas object\n",
    "        y: Current state\n",
    "        t: Current time\n",
    "        timestep: Time step size\n",
    "        rtol: Relative tolerance\n",
    "        atol: Absolute tolerance\n",
    "    \n",
    "    Returns:\n",
    "        result: Dictionary with integration results\n",
    "    \"\"\"\n",
    "    t_end = t + timestep\n",
    "    previous_state = y.copy()\n",
    "    \n",
    "    try:\n",
    "        # Create solver\n",
    "        solver = create_solver(method, gas, y, t, rtol, atol, t_end, pressure=pressure, table_id=table_id)\n",
    "        \n",
    "        # Integrate\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if method.startswith('cpp_'):\n",
    "            result = rk_solver_cpp.solve_ivp(solver, np.array(t_end))\n",
    "            new_y = result['y'][-1]\n",
    "            # ensure that new_y is not empty\n",
    "            if len(new_y) == 0:\n",
    "                print(\"new_y is empty\")\n",
    "                print(result)\n",
    "        elif method.startswith('scipy_'):\n",
    "            solver.integrate(t_end)\n",
    "            new_y = solver.y\n",
    "        else:  # SUNDIALS\n",
    "            new_y = solver.solve_single(t_end)\n",
    "        \n",
    "        cpu_time = time.time() - start_time\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            't': t_end,\n",
    "            'y': new_y,\n",
    "            'cpu_time': cpu_time,\n",
    "            'fuel_mass_fraction': gas.mass_fraction_dict()[fuel] if fuel in gas.mass_fraction_dict().keys() else 0.0,\n",
    "            'error': 0.0,\n",
    "            'message': 'Success',\n",
    "            'timed_out': False,\n",
    "            'previous_state': previous_state\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Step {t} failed: {e}\")\n",
    "        return {\n",
    "            'success': False,\n",
    "            't': t,\n",
    "            'y': previous_state,\n",
    "            'fuel_mass_fraction': gas.mass_fraction_dict()[fuel] if fuel in gas.mass_fraction_dict().keys() else 0.0,\n",
    "            'cpu_time': 0.0,\n",
    "            'error': float('inf'),\n",
    "            'message': str(e),\n",
    "            'timed_out': False,\n",
    "            'previous_state': previous_state\n",
    "        }\n",
    "\n",
    "def run_integration_experiment(method: str, gas: ct.Solution, y0: np.ndarray, \n",
    "                             t0: float, end_time: float, timestep: float,\n",
    "                             rtol: float, atol: float, species_to_track: List[str],\n",
    "                             fuel: str, pressure: float=ct.one_atm,\n",
    "                             time_limit: float = 300.0, table_id: Optional[SP.arkode.ButcherTable] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Run a complete integration experiment with the specified method.\n",
    "    \n",
    "    Args:\n",
    "        method: Solver method to test\n",
    "        gas: Cantera gas object\n",
    "        y0: Initial state\n",
    "        t0: Start time\n",
    "        end_time: End time\n",
    "        timestep: Time step size\n",
    "        rtol: Relative tolerance\n",
    "        atol: Absolute tolerance\n",
    "        species_to_track: List of species to monitor\n",
    "        fuel: Fuel name\n",
    "        time_limit: Maximum allowed wall clock time in seconds (default 300s)\n",
    "    \n",
    "    Returns:\n",
    "        results: Dictionary with complete integration results\n",
    "    \"\"\"\n",
    "    # Initialize tracking arrays\n",
    "    times = [t0]\n",
    "    temperatures = [y0[0]]\n",
    "    species_profiles = {spec: [y0[gas.species_index(spec) + 1]] for spec in species_to_track}\n",
    "    cpu_times = []\n",
    "    fuel_mass_fractions = []\n",
    "    \n",
    "    # Integration loop\n",
    "    t = t0\n",
    "    y = y0.copy()\n",
    "    step_count = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    bar = tqdm(total=end_time, desc=f\"Running {method}-{str(table_id)} with rtol={rtol} and atol={atol}\")\n",
    "    while t < end_time:\n",
    "        bar.update(timestep)\n",
    "        # Check if time limit exceeded\n",
    "        if time.time() - start_time > time_limit:\n",
    "            print(f\"Time limit of {time_limit}s exceeded after {step_count} steps\")\n",
    "            break\n",
    "            \n",
    "        result = integrate_single_step(method, gas, y, t, timestep, rtol, atol, fuel, pressure=pressure, table_id=table_id)\n",
    "        \n",
    "        if not result['success']:\n",
    "            print(f\"Step {step_count} failed: {result['message']}\")\n",
    "            break\n",
    "        \n",
    "        # Update state\n",
    "        y = result['y']\n",
    "        t = result['t']\n",
    "        cpu_times.append(result['cpu_time'])\n",
    "        step_count += 1\n",
    "        fuel_mass_fractions.append(result['fuel_mass_fraction'])\n",
    "\n",
    "        # ensure that y is not empty\n",
    "        if len(y) == 0:\n",
    "            print(f\"Step {step_count} failed: y is empty\")\n",
    "            print(result)\n",
    "            print(y)\n",
    "            break\n",
    "        \n",
    "        # Record data\n",
    "        times.append(t)\n",
    "        temperatures.append(y[0])\n",
    "        for spec in species_to_track:\n",
    "            species_profiles[spec].append(y[gas.species_index(spec) + 1])\n",
    "        \n",
    "        #print(f\"Step {step_count} at time {t:.2e} - temperature {y[0]:.1f}K - CPU time {cpu_times[-1]:.2e}s - time taken {time.time() - start_time:.2f}s | {np.sum(cpu_times):.2e}s\")\n",
    "        bar.set_postfix({\n",
    "            'step': f\"{step_count}\",\n",
    "            'temperature': f\"{y[0]:.1f}K\",\n",
    "            'cpu_time': f\"{cpu_times[-1]:.2e}s\",\n",
    "            'total_cpu_time': f\"{np.sum(cpu_times):.2e}s\"\n",
    "        })\n",
    "    bar.close() \n",
    "    total_wall_time = time.time() - start_time\n",
    "    return {\n",
    "        'method': method,\n",
    "        'phi': gas.equivalence_ratio,\n",
    "        'rtol': rtol,\n",
    "        'atol': atol,   \n",
    "        'times': np.array(times),\n",
    "        'fuel_mass_fractions': np.array(fuel_mass_fractions),\n",
    "        'temperatures': np.array(temperatures),\n",
    "        'species_profiles': species_profiles,\n",
    "        'cpu_times': np.array(cpu_times),\n",
    "        'total_cpu_time': np.sum(cpu_times),\n",
    "        'total_wall_time': total_wall_time,\n",
    "        'steps': step_count,\n",
    "        'success': step_count > 0,\n",
    "        'timed_out': total_wall_time > time_limit\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "452aaf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_combustion_chemistry_with_data(mechanism: str,temperature: float, pressure: float, data: np.ndarray) -> ct.Solution:\n",
    "    \"\"\"Set up the combustion chemistry with Cantera.\n",
    "    \n",
    "    Args:\n",
    "        mechanism: Path to mechanism file\n",
    "        fuel: Fuel species name\n",
    "        oxidizer: Oxidizer mixture string\n",
    "        phi: Equivalence ratio\n",
    "        temperature: Initial temperature (K)\n",
    "        pressure: Initial pressure (Pa)\n",
    "    \n",
    "    Returns:\n",
    "        gas: Initialized Cantera gas object\n",
    "    \"\"\"\n",
    "    gas = ct.Solution(mechanism)\n",
    "    gas.TPX = temperature, pressure, data\n",
    "    return gas\n",
    "\n",
    "def get_initial_state(gas: ct.Solution) -> np.ndarray:\n",
    "    \"\"\"Get initial state vector [T, Y1, Y2, ...].\n",
    "    \n",
    "    Args:\n",
    "        gas: Cantera gas object\n",
    "    \n",
    "    Returns:\n",
    "        y: Initial state vector\n",
    "    \"\"\"\n",
    "    return np.hstack([gas.T, gas.Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95c759b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def detect_ignition_regions(temperature_profile, time_array=None, \n",
    "                           gradient_threshold=None, smooth_sigma=1.0,\n",
    "                           min_ignition_length=5):\n",
    "    \"\"\"\n",
    "    Detect pre-ignition, ignition, and post-ignition regions in a temperature profile.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    temperature_profile : array-like\n",
    "        Temperature values over time\n",
    "    time_array : array-like, optional\n",
    "        Time values corresponding to temperature measurements.\n",
    "        If None, assumes uniform spacing with indices.\n",
    "    gradient_threshold : float, optional\n",
    "        Threshold for detecting ignition based on temperature gradient.\n",
    "        If None, automatically determined from data.\n",
    "    smooth_sigma : float, default=1.0\n",
    "        Gaussian smoothing parameter for gradient calculation\n",
    "    min_ignition_length : int, default=5\n",
    "        Minimum number of points for ignition region\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (pre_ignition_end_idx, ignition_start_idx, ignition_end_idx)\n",
    "        - pre_ignition_end_idx: Last index of pre-ignition region\n",
    "        - ignition_start_idx: First index of ignition region  \n",
    "        - ignition_end_idx: Last index of ignition region\n",
    "        Post-ignition starts at ignition_end_idx + 1\n",
    "    \"\"\"\n",
    "    \n",
    "    temp = np.array(temperature_profile)\n",
    "    n_points = len(temp)\n",
    "    \n",
    "    if time_array is None:\n",
    "        time_array = np.arange(n_points)\n",
    "    else:\n",
    "        time_array = np.array(time_array)\n",
    "    \n",
    "    # Calculate smoothed gradient\n",
    "    temp_smooth = gaussian_filter1d(temp, sigma=smooth_sigma)\n",
    "    dt = np.diff(time_array)\n",
    "    dt = np.append(dt, dt[-1])  # Extend to same length\n",
    "    gradient = np.gradient(temp_smooth) / dt\n",
    "    \n",
    "    # Auto-determine threshold if not provided\n",
    "    if gradient_threshold is None:\n",
    "        # Use a multiple of the standard deviation of the gradient\n",
    "        gradient_std = np.std(gradient)\n",
    "        gradient_mean = np.mean(gradient)\n",
    "        gradient_threshold = gradient_mean + 3 * gradient_std\n",
    "    \n",
    "    # Find regions where gradient exceeds threshold\n",
    "    high_gradient_mask = gradient > gradient_threshold\n",
    "    \n",
    "    # Find the start and end of the main ignition event\n",
    "    # Look for the longest continuous region above threshold\n",
    "    high_gradient_indices = np.where(high_gradient_mask)[0]\n",
    "    \n",
    "    if len(high_gradient_indices) == 0:\n",
    "        # No ignition detected, return boundaries assuming late ignition\n",
    "        return n_points//3, 2*n_points//3, n_points-1\n",
    "    \n",
    "    # Find continuous regions\n",
    "    diff_indices = np.diff(high_gradient_indices)\n",
    "    breaks = np.where(diff_indices > 1)[0]\n",
    "    \n",
    "    if len(breaks) == 0:\n",
    "        # Single continuous region\n",
    "        ignition_start_idx = high_gradient_indices[0]\n",
    "        ignition_end_idx = high_gradient_indices[-1]\n",
    "    else:\n",
    "        # Multiple regions - find the longest one\n",
    "        region_starts = [high_gradient_indices[0]] + [high_gradient_indices[b+1] for b in breaks]\n",
    "        region_ends = [high_gradient_indices[b] for b in breaks] + [high_gradient_indices[-1]]\n",
    "        region_lengths = [end - start for start, end in zip(region_starts, region_ends)]\n",
    "        \n",
    "        longest_region_idx = np.argmax(region_lengths)\n",
    "        ignition_start_idx = region_starts[longest_region_idx]\n",
    "        ignition_end_idx = region_ends[longest_region_idx]\n",
    "    \n",
    "    # Extend ignition region if too short\n",
    "    if ignition_end_idx - ignition_start_idx < min_ignition_length:\n",
    "        center = (ignition_start_idx + ignition_end_idx) // 2\n",
    "        half_length = min_ignition_length // 2\n",
    "        ignition_start_idx = max(0, center - half_length)\n",
    "        ignition_end_idx = min(n_points - 1, center + half_length)\n",
    "    \n",
    "    # Pre-ignition ends just before ignition starts\n",
    "    pre_ignition_end_idx = max(0, ignition_start_idx - 1)\n",
    "    \n",
    "    # Ensure ignition_end_idx doesn't exceed array bounds\n",
    "    ignition_end_idx = min(ignition_end_idx, n_points - 1)\n",
    "    \n",
    "    return pre_ignition_end_idx, ignition_start_idx, ignition_end_idx\n",
    "\n",
    "\n",
    "def plot_regions(temperature_profile, time_array=None, region_indices=None):\n",
    "    \"\"\"\n",
    "    Plot temperature profile with detected regions highlighted.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    temperature_profile : array-like\n",
    "        Temperature values\n",
    "    time_array : array-like, optional\n",
    "        Time values\n",
    "    region_indices : tuple, optional\n",
    "        (pre_ignition_end_idx, ignition_start_idx, ignition_end_idx)\n",
    "        If None, will detect automatically\n",
    "    \"\"\"\n",
    "    \n",
    "    if time_array is None:\n",
    "        time_array = np.arange(len(temperature_profile))\n",
    "    \n",
    "    if region_indices is None:\n",
    "        region_indices = detect_ignition_regions(temperature_profile, time_array)\n",
    "    \n",
    "    pre_end, ign_start, ign_end = region_indices\n",
    "    \n",
    "    plt.figure(figsize=(10, 6), dpi=200)\n",
    "    plt.plot(time_array, temperature_profile, 'b-', linewidth=2, label='Temperature')\n",
    "    \n",
    "    # Highlight regions\n",
    "    plt.axvspan(time_array[0], time_array[pre_end], alpha=0.3, color='green', \n",
    "                label='Pre-ignition')\n",
    "    plt.axvspan(time_array[ign_start], time_array[ign_end], alpha=0.3, color='red', \n",
    "                label='Ignition')\n",
    "    plt.axvspan(time_array[ign_end], time_array[-1], alpha=0.3, color='blue', \n",
    "                label='Post-ignition')\n",
    "    \n",
    "    # Add vertical lines at boundaries\n",
    "    plt.axvline(time_array[pre_end], color='green', linestyle='--', alpha=0.7)\n",
    "    plt.axvline(time_array[ign_start], color='red', linestyle='--', alpha=0.7)\n",
    "    plt.axvline(time_array[ign_end], color='red', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Temperature (K)')\n",
    "    plt.title('Temperature Profile with Detected Regions')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97bb5df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def running_average_forward(array, window_size):\n",
    "    \"\"\"\n",
    "    Calculate running average where each point uses the window starting from that point.\n",
    "    Returns array of same length as input.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    array : array-like\n",
    "        Input array\n",
    "    window_size : int\n",
    "        Size of the averaging window\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Running average array of same length as input\n",
    "    \"\"\"\n",
    "    array = np.array(array)\n",
    "    n = len(array)\n",
    "    result = np.zeros(n)\n",
    "    \n",
    "    # Calculate number of complete windows\n",
    "    num_windows = (n + window_size - 1) // window_size\n",
    "    \n",
    "    # Process each window\n",
    "    for w in range(num_windows):\n",
    "        start_idx = w * window_size\n",
    "        end_idx = min((w + 1) * window_size, n)\n",
    "        window_mean = np.mean(array[start_idx:end_idx])\n",
    "        \n",
    "        # Fill result array for all points that use this window\n",
    "        result[start_idx:end_idx] = window_mean\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeabc76",
   "metadata": {},
   "source": [
    "# TOLERANCE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e696ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(ref_data, test_data, species_name, use_log=False):\n",
    "    rmse_dict = {}\n",
    "    for specie_name in species_name:\n",
    "        if specie_name == 'temperature':\n",
    "            ref_profile = ref_data['temperatures']\n",
    "            test_profile = test_data['temperatures']\n",
    "        else:\n",
    "            ref_profile = ref_data['species_profiles'][specie_name]\n",
    "            test_profile = test_data['species_profiles'][specie_name]\n",
    "        if use_log:\n",
    "            ref_profile = np.log10(np.maximum(ref_profile, 1e-20))\n",
    "            test_profile = np.log10(np.maximum(test_profile, 1e-20))\n",
    "        else:\n",
    "            ref_profile = np.array(ref_profile)\n",
    "            test_profile = np.array(test_profile)\n",
    "            size = min(ref_profile.shape[0], test_profile.shape[0])\n",
    "            ref_profile = ref_profile[:size]\n",
    "            test_profile = test_profile[:size]\n",
    "        rmse = np.sqrt((ref_profile- test_profile) ** 2)\n",
    "        rmse_dict[specie_name] = rmse\n",
    "    return rmse_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55e38aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_gas(temperature=600, pressure=101325, phi=1):\n",
    "    gas = ct.Solution(mechanism_file)\n",
    "    gas.set_equivalence_ratio(phi, fuel, 'O2:1, N2:3.76')\n",
    "    gas.TPX = temperature, pressure, gas.X\n",
    "    y0 = get_initial_state(gas)\n",
    "    return gas, y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9a79ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of implicit solvers = 12\n",
      "Number of explicit solvers = 9\n"
     ]
    }
   ],
   "source": [
    "implicit_solvers = [SP.arkode.ButcherTable.ARK2_DIRK_3_1_2, SP.arkode.ButcherTable.ESDIRK325L2SA_5_2_3, \n",
    "                    SP.arkode.ButcherTable.TRBDF2_3_3_2, SP.arkode.ButcherTable.ESDIRK436L2SA_6_3_4, SP.arkode.ButcherTable.ESDIRK43I6L2SA_6_3_4, \n",
    "                    SP.arkode.ButcherTable.QESDIRK436L2SA_6_3_4, \n",
    "                    SP.arkode.ButcherTable.CASH_5_2_4, SP.arkode.ButcherTable.CASH_5_3_4, SP.arkode.ButcherTable.SDIRK_5_3_4, \n",
    "                    SP.arkode.ButcherTable.ARK436L2SA_DIRK_6_3_4, SP.arkode.ButcherTable.ESDIRK437L2SA_7_3_4, SP.arkode.ButcherTable.ARK437L2SA_DIRK_7_3_4]\n",
    "\n",
    "print(f\"Number of implicit solvers = {len(implicit_solvers)}\")\n",
    "\n",
    "explicit_solvers = [SP.arkode.ButcherTable.HEUN_EULER_2_1_2 , SP.arkode.ButcherTable.BOGACKI_SHAMPINE_4_2_3,\n",
    "        SP.arkode.ButcherTable.ARK324L2SA_ERK_4_2_3, SP.arkode.ButcherTable.ZONNEVELD_5_3_4,\n",
    "        SP.arkode.ButcherTable.ARK436L2SA_ERK_6_3_4, SP.arkode.ButcherTable.ARK437L2SA_ERK_7_3_4,\n",
    "        SP.arkode.ButcherTable.ARK548L2SA_ERK_8_4_5,\n",
    "        SP.arkode.ButcherTable.VERNER_8_5_6,\n",
    "        SP.arkode.ButcherTable.FEHLBERG_13_7_8]\n",
    "\n",
    "print(f\"Number of explicit solvers = {len(explicit_solvers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613e128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_to_plot = [SP.arkode.ButcherTable.ARK2_DIRK_3_1_2, SP.arkode.ButcherTable.TRBDF2_3_3_2, SP.arkode.ButcherTable.HEUN_EULER_2_1_2 , SP.arkode.ButcherTable.BOGACKI_SHAMPINE_4_2_3]\n",
    "\n",
    "print(f\"Number of solvers to plot = {len(solver_to_plot)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc37cc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 500\n",
    "pressure = 101325\n",
    "phi = 1\n",
    "gas, y0 = reset_gas(temperature, pressure, phi)\n",
    "t0 = 0.0\n",
    "end_time = 2e-2\n",
    "timestep = 1e-6\n",
    "species_to_track = gas.species_names\n",
    "fuel = 'nc12h26'\n",
    "time_limit = 120.0\n",
    "table_id = SP.arkode.ButcherTable.HEUN_EULER_2_1_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da491306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for different runs\n",
    "run_params = [\n",
    "    ('reference', 1e-12, 1e-10),\n",
    "    ('bdf_results_high', 1e-8, 1e-10), \n",
    "    ('bdf_results_low', 1e-6, 1e-8)\n",
    "]\n",
    "\n",
    "bdf_results = {}\n",
    "\n",
    "# Loop through parameters and run experiments\n",
    "for result_name, rtol, atol in run_params:\n",
    "    gas, y0 = reset_gas(temperature, pressure, phi)\n",
    "    method = 'cvode_bdf'\n",
    "    \n",
    "    results = run_integration_experiment(\n",
    "                method, gas, y0, t0, end_time, timestep,\n",
    "                rtol, atol, species_to_track,\n",
    "                fuel, pressure=gas.P,\n",
    "                time_limit=time_limit,\n",
    "                table_id=None\n",
    "            )\n",
    "    \n",
    "    bdf_results[result_name] = results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bec5148",
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers_results_high = {}\n",
    "for table_id in solver_to_plot:\n",
    "    if table_id in implicit_solvers:\n",
    "        method = 'arkode_dirk'\n",
    "    else:\n",
    "        method = 'arkode_erk'\n",
    "    gas, y0 = reset_gas(temperature, pressure, phi)\n",
    "    rtol, atol = 1e-8, 1e-10\n",
    "\n",
    "    bdf_results = run_integration_experiment(\n",
    "                method, gas, y0, t0, end_time, timestep,\n",
    "                rtol, atol, species_to_track,\n",
    "                fuel, pressure=gas.P,\n",
    "                time_limit=time_limit,\n",
    "                table_id=table_id\n",
    "            )\n",
    "    solvers_results_high[table_id] = bdf_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1fffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers_results_low = {}\n",
    "for table_id in solver_to_plot:\n",
    "    if table_id in implicit_solvers:\n",
    "        method = 'arkode_dirk'\n",
    "    else:\n",
    "        method = 'arkode_erk'\n",
    "    gas, y0 = reset_gas(temperature, pressure, phi)\n",
    "    rtol, atol = 1e-6, 1e-8\n",
    "\n",
    "    bdf_results = run_integration_experiment(\n",
    "                method, gas, y0, t0, end_time, timestep,\n",
    "                rtol, atol, species_to_track,\n",
    "                fuel, pressure=gas.P,\n",
    "                time_limit=time_limit,\n",
    "                table_id=table_id\n",
    "            )\n",
    "    solvers_results_low[table_id] = bdf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0b66fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT THE CPU TIME OF THE IMPLICIT SOLVERS IN A 2x2 GRID\n",
    "line_styles = ['-', '--', '-.', ':'] * 10  # Repeat basic line styles\n",
    "colors = [ 'purple', 'orange', 'brown', 'pink', 'gray', 'olive', 'cyan', 'magenta', 'lime', 'teal', 'navy', 'maroon', 'gold', 'silver', 'indigo', 'turquoise']\n",
    "\n",
    "# Create figure with 2x2 subplots sharing x and y axes\n",
    "fig, ax = plt.subplots(figsize=(15, 10), dpi=200)\n",
    "\n",
    "# Plot each group in its own subplot\n",
    "for i, table_id in enumerate(solver_to_plot):\n",
    "    # if table_id in solver_to_exclude:\n",
    "    #     continue\n",
    "    data = solvers_results_high[table_id]\n",
    "    ax.plot(\n",
    "        running_average_forward(data['cpu_times'], 1000),\n",
    "        label=f\"{str(table_id)} - {np.sum(data['cpu_times']):.2e}\",\n",
    "        linestyle=line_styles[i],\n",
    "        linewidth=2,\n",
    "        color=colors[i]\n",
    "    )\n",
    "ax.plot(\n",
    "    running_average_forward(bdf_results['reference']['cpu_times'], 1000    ),\n",
    "    label=f'Reference(1e-12,1e-10) - {np.sum(bdf_results['reference']['cpu_times']):.2e}',\n",
    "    linestyle='-',\n",
    "    linewidth=3,\n",
    "    color='red'\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    running_average_forward(bdf_results['bdf_results_low']['cpu_times'], 1000),\n",
    "    label=f'BDF(1e-6,1e-8) - {np.sum(bdf_results['bdf_results_low']['cpu_times']):.2e}',\n",
    "    linestyle='-',\n",
    "    linewidth=2,\n",
    "    color='blue'\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    running_average_forward(bdf_results['bdf_results_high']['cpu_times'], 1000),\n",
    "    label=f'BDF(1e-8,1e-10) - {np.sum(bdf_results['bdf_results_high']['cpu_times']):.2e}',\n",
    "    linestyle='-',\n",
    "    linewidth=2,\n",
    "    color='green'\n",
    ")\n",
    "# ax.set_title(f'Solvers {subplot_idx*6 + 1}-{min((subplot_idx+1)*6, 25)}')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# # Set common labels\n",
    "# fig.text(0.5, 0.04, 'Step Number', ha='center', va='center')\n",
    "# fig.text(0.06, 0.5, 'CPU Time (s)', ha='center', va='center', rotation='vertical')\n",
    "fig.suptitle(f'CPU Time per Step for Different Implicit Solvers - {temperature}K - {pressure}Pa', fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8cd630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT THE CPU TIME OF THE IMPLICIT SOLVERS IN A 2x2 GRID\n",
    "line_styles = ['-', '--', '-.', ':'] * 10  # Repeat basic line styles\n",
    "colors = [ 'purple', 'orange', 'brown', 'pink', 'gray', 'olive', 'cyan', 'magenta', 'lime', 'teal', 'navy', 'maroon', 'gold', 'silver', 'indigo', 'turquoise']\n",
    "\n",
    "# Create figure with 2x2 subplots sharing x and y axes\n",
    "fig, ax = plt.subplots(figsize=(15, 10), dpi=200)\n",
    "\n",
    "# Plot each group in its own subplot\n",
    "for i, table_id in enumerate(solver_to_plot):\n",
    "    # if table_id in solver_to_exclude:\n",
    "    #     continue\n",
    "    data = solvers_results_high[table_id]\n",
    "    ax.plot(\n",
    "        running_average_forward(data['cpu_times'], 1000),\n",
    "        label=f\"{str(table_id)} - {np.sum(data['cpu_times']):.2e}\",\n",
    "        linestyle=line_styles[i],\n",
    "        linewidth=2,\n",
    "        color=colors[i]\n",
    "    )\n",
    "ax.plot(\n",
    "    running_average_forward(reference_results['cpu_times'], 1000    ),\n",
    "    label=f'Reference(1e-12,1e-10) - {np.sum(reference_results['cpu_times']):.2e}',\n",
    "    linestyle='-',\n",
    "    linewidth=3,\n",
    "    color='red'\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    running_average_forward(bdf_results['cpu_times'], 1000),\n",
    "    label=f'BDF(1e-6,1e-8) - {np.sum(bdf_results['cpu_times']):.2e}',\n",
    "    linestyle='-',\n",
    "    linewidth=2,\n",
    "    color='blue'\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    running_average_forward(bdf_results_high['cpu_times'], 1000),\n",
    "    label=f'BDF(1e-8,1e-10) - {np.sum(bdf_results_high['cpu_times']):.2e}',\n",
    "    linestyle='-',\n",
    "    linewidth=2,\n",
    "    color='green'\n",
    ")\n",
    "# ax.set_title(f'Solvers {subplot_idx*6 + 1}-{min((subplot_idx+1)*6, 25)}')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# # Set common labels\n",
    "# fig.text(0.5, 0.04, 'Step Number', ha='center', va='center')\n",
    "# fig.text(0.06, 0.5, 'CPU Time (s)', ha='center', va='center', rotation='vertical')\n",
    "fig.suptitle(f'CPU Time per Step for Different Implicit Solvers - {temperature}K - {pressure}Pa', fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fecee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_errors = {}\n",
    "solver_errors_high = {}\n",
    "explicit_solver_errors = {}\n",
    "species_to_track = ['temperature', 'h', 'h2', 'o', 'o2', 'h2o', 'ho2', 'h2o2', 'oh']\n",
    "for table_id in solver_to_plot:\n",
    "    solver_errors[table_id] = calculate_rmse(reference_results, solvers_results_low[table_id], species_to_track, use_log=False)\n",
    "    solver_errors_high[table_id] = calculate_rmse(reference_results, solvers_results_high[table_id], species_to_track, use_log=False)\n",
    "\n",
    "\n",
    "bdf_results_errors = calculate_rmse(reference_results, bdf_results, species_to_track, use_log=False)\n",
    "\n",
    "bdf_results_errors_high = calculate_rmse(reference_results, bdf_results_high, species_to_track, use_log=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb2154",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_to_exclude = [SP.arkode.ButcherTable.HEUN_EULER_2_1_2 , SP.arkode.ButcherTable.ARK324L2SA_ERK_4_2_3, SP.arkode.ButcherTable.ARK437L2SA_DIRK_7_3_4, SP.arkode.ButcherTable.BOGACKI_SHAMPINE_4_2_3, SP.arkode.ButcherTable.CASH_5_3_4, SP.arkode.ButcherTable.HEUN_EULER_2_1_2]\n",
    "solver_to_plot = [SP.arkode.ButcherTable.ARK2_DIRK_3_1_2, SP.arkode.ButcherTable.TRBDF2_3_3_2, SP.arkode.ButcherTable.HEUN_EULER_2_1_2 , SP.arkode.ButcherTable.BOGACKI_SHAMPINE_4_2_3,\n",
    "                  SP.arkode.ButcherTable.CASH_5_3_4, SP.arkode.ButcherTable.ARK437L2SA_DIRK_7_3_4,  SP.arkode.ButcherTable.ARK324L2SA_ERK_4_2_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faab4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create one large figure with subplots for all species\n",
    "fig, axes = plt.subplots(3, 3, figsize=(30, 30), dpi=300)\n",
    "\n",
    "for i, specie_name in enumerate(species_to_track):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    for j, table_id in enumerate(solver_to_plot):\n",
    "        # if table_id in solver_to_exclude:\n",
    "        #     continue\n",
    "        data = solver_errors_high[table_id]\n",
    "        ax.plot(np.maximum(data[specie_name], 1e-20),\n",
    "            label=f\"{str(table_id)}\", \n",
    "            linestyle=line_styles[j % len(line_styles)],\n",
    "            linewidth=2,\n",
    "                color=colors[j % len(colors)])\n",
    "        \n",
    "    ax.plot(np.maximum(bdf_results_errors[specie_name], 1e-20),\n",
    "            label=f\"BDF(1e-6,1e-8)\", \n",
    "            linestyle='-',\n",
    "            linewidth=2,\n",
    "                color='red')\n",
    "    ax.plot(np.maximum(bdf_results_errors_high[specie_name], 1e-20),\n",
    "            label=f\"BDF(1e-8,1e-10)\", \n",
    "            linestyle='-',\n",
    "            linewidth=2,\n",
    "                color='blue')\n",
    "    ax.set_title(f'{specie_name}')\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid(True)\n",
    "    if i == len(species_to_track) - 1:  # Only show legend on last plot\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "fig.suptitle('RMSE for Different Species Across All Implicit Solvers', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacd490f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c9e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit_solver_errors = {}\n",
    "species_to_track = ['temperature', 'h', 'h2', 'o', 'o2', 'h2o', 'ho2', 'h2o2', 'oh']\n",
    "for table_id in implicit_solvers:\n",
    "    implicit_solver_errors[table_id] = calculate_rmse(reference_results, implicit_results[table_id], species_to_track, use_log=False)\n",
    "\n",
    "# Create one large figure with subplots for all species\n",
    "fig, axes = plt.subplots(3, 3, figsize=(30, 30), dpi=300)\n",
    "\n",
    "for i, specie_name in enumerate(species_to_track):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    for j, table_id in enumerate(implicit_solvers):\n",
    "        ax.plot(np.maximum(implicit_solver_errors[table_id][specie_name], 1e-20),\n",
    "            label=f\"{str(table_id)}\", \n",
    "            linestyle=line_styles[j % len(line_styles)],\n",
    "            linewidth=2,\n",
    "                color=colors[j % len(colors)])\n",
    "    ax.set_title(f'{specie_name}')\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid(True)\n",
    "    if i == len(species_to_track) - 1:  # Only show legend on last plot\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "fig.suptitle('RMSE for Different Species Across All Implicit Solvers', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6d41f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT THE CPU TIME OF THE IMPLICIT SOLVERS IN A 2x2 GRID\n",
    "line_styles = ['-', '--', '-.', ':'] * 10  # Repeat basic line styles\n",
    "colors = ['blue', 'green', 'purple', 'orange', 'brown', 'pink', 'gray', 'olive', 'cyan', 'magenta', 'lime', 'teal', 'navy', 'maroon', 'gold', 'silver', 'indigo', 'turquoise']\n",
    "\n",
    "# Create figure with 2x2 subplots sharing x and y axes\n",
    "fig, axs = plt.subplots(2, 2, figsize=(25, 20), dpi=300, sharex=True, sharey=True)\n",
    "axs = axs.ravel()  # Flatten axes array for easier indexing\n",
    "\n",
    "# Split solvers into 4 groups (first 3 groups of 6, last group of 7)\n",
    "solver_groups = [implicit_solvers[i:i + 6] for i in range(0, 18, 6)]\n",
    "solver_groups.append(implicit_solvers[18:])  # Add remaining 7 solvers\n",
    "\n",
    "# Plot each group in its own subplot\n",
    "for subplot_idx, solver_group in enumerate(solver_groups):\n",
    "    for i, table_id in enumerate(solver_group):\n",
    "        axs[subplot_idx].plot(\n",
    "            running_average_forward(implicit_results[table_id]['cpu_times'], 200),\n",
    "            label=f\"{str(table_id)} - {np.sum(implicit_results[table_id]['cpu_times']):.2e}\",\n",
    "            linestyle=line_styles[i],\n",
    "            linewidth=2,\n",
    "            color=colors[i]\n",
    "        )\n",
    "    axs[subplot_idx].plot(\n",
    "        running_average_forward(reference_results['cpu_times'], 100),\n",
    "        label=f'Reference - {np.sum(reference_results['cpu_times']):.2e}',\n",
    "        linestyle='-',\n",
    "        linewidth=3,\n",
    "        color='red'\n",
    "    )\n",
    "    axs[subplot_idx].set_title(f'Solvers {subplot_idx*6 + 1}-{min((subplot_idx+1)*6, 25)}')\n",
    "    axs[subplot_idx].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "# # Set common labels\n",
    "# fig.text(0.5, 0.04, 'Step Number', ha='center', va='center')\n",
    "# fig.text(0.06, 0.5, 'CPU Time (s)', ha='center', va='center', rotation='vertical')\n",
    "fig.suptitle(f'CPU Time per Step for Different Implicit Solvers - {temperature}K - {pressure}Pa', fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82966ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas, y0 = reset_gas(temperature, pressure, mixture_fractions)\n",
    "method = 'cvode_bdf'\n",
    "rtol, atol = 1e-8, 1e-8\n",
    "\n",
    "bdf_results = run_integration_experiment(\n",
    "                method, gas, y0, t0, end_time, timestep,\n",
    "                rtol, atol, species_to_track,\n",
    "                fuel, pressure=gas.P,\n",
    "                time_limit=time_limit,\n",
    "                table_id=table_id\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b5ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "37.8/1.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fdb3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas, y0 = reset_gas(temperature, pressure, mixture_fractions)\n",
    "method = 'cpp_rk23'\n",
    "rtol, atol = 1e-12, 1e-10\n",
    "\n",
    "rk_results_high = run_integration_experiment(\n",
    "                method, gas, y0, t0, end_time, timestep,\n",
    "                rtol, atol, species_to_track,\n",
    "                fuel, pressure=gas.P,\n",
    "                time_limit=time_limit,\n",
    "                table_id=table_id\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8568e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gas, y0 = reset_gas(temperature, pressure, mixture_fractions)\n",
    "method = 'cpp_rk23'\n",
    "rtol, atol = 1e-8, 1e-8\n",
    "\n",
    "rk_results_low = run_integration_experiment(\n",
    "                method, gas, y0, t0, end_time, timestep,\n",
    "                rtol, atol, species_to_track,\n",
    "                fuel, pressure=gas.P,\n",
    "                time_limit=time_limit,\n",
    "                table_id=table_id\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaba60e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_comparison_rk_high = calculate_rmse(reference_results, rk_results_high, ['temperature', 'h', 'h2', 'o', 'o2', 'h2o', 'ho2', 'h2o2', 'oh'], use_log=False)\n",
    "error_comparison_rk_low = calculate_rmse(reference_results, rk_results_low, ['temperature', 'h', 'h2', 'o', 'o2', 'h2o', 'ho2', 'h2o2', 'oh'], use_log=False)\n",
    "error_comparison_bdf = calculate_rmse(reference_results, bdf_results, ['temperature', 'h', 'h2', 'o', 'o2', 'h2o', 'ho2', 'h2o2', 'oh'], use_log=False)\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 20), dpi=200)\n",
    "\n",
    "for i, specie_name in enumerate(error_comparison_rk_high.keys()):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    ax.plot(reference_results['times'], np.maximum(error_comparison_rk_high[specie_name], 1e-20), label='RK23 (rtol=1e-8, atol=1e-8)', color='red', linestyle='-.')\n",
    "    ax.plot(reference_results['times'], np.maximum(error_comparison_rk_low[specie_name], 1e-20), label='RK23 (rtol=1e-12, atol=1e-10)', linestyle='--', color='blue')\n",
    "    ax.plot(reference_results['times'], np.maximum(error_comparison_bdf[specie_name], 1e-20), label='BDF (rtol=1e-8, atol=1e-8)', linestyle='--', color='green')\n",
    "    ax.set_title(f\"{specie_name} RMSE\")\n",
    "    ax.legend()\n",
    "\n",
    "# i want to add a text box to the figure\n",
    "fig.text(0.5, 0.01, \"NOTE: The the error is maxed to 1e-20 for better visualization\", ha='center', va='center', fontsize=12)\n",
    "fig.suptitle(f\"Temperature {temperature}K - Pressure {pressure}Pa\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5edd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_times = []\n",
    "fuel_mass_fractions = []\n",
    "times = []\n",
    "temperatures = []\n",
    "species_profiles = {spec: [] for spec in species_to_track}\n",
    "method = 'arkode_dirk'\n",
    "table_id = SP.arkode.ButcherTable.TRBDF2_3_3_2\n",
    "rtol, atol = 1e-6, 1e-8\n",
    "\n",
    "end_time = 2e-2\n",
    "t0 = 0.0\n",
    "temperature = 400\n",
    "index = 37\n",
    "sample = df_filtered_array[index]\n",
    "pressure = sample[1]\n",
    "mixture_fractions = sample[4:]\n",
    "gas, y0 = reset_gas(temperature, pressure, mixture_fractions)\n",
    "t = 0.0\n",
    "\n",
    "timestep = 1e-5\n",
    "t = t0\n",
    "y = y0.copy()\n",
    "step_count = 0\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9145bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = integrate_single_step(method, gas, y, t, timestep, rtol, atol, fuel, pressure=pressure, table_id=table_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['cpu_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23388487",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cpu_times = []\n",
    "fuel_mass_fractions = []\n",
    "times = []\n",
    "temperatures = []\n",
    "species_profiles = {spec: [] for spec in species_to_track}\n",
    "method = 'arkode_dirk'\n",
    "table_id = SP.arkode.ButcherTable.BILLINGTON_3_3_2\n",
    "rtol, atol = 1e-6, 1e-8\n",
    "\n",
    "end_time = 2e-2\n",
    "t0 = 0.0\n",
    "temperature = 400\n",
    "index = 37\n",
    "sample = df_filtered_array[index]\n",
    "pressure = sample[1]\n",
    "mixture_fractions = sample[4:]\n",
    "gas, y0 = reset_gas(temperature, pressure, mixture_fractions)\n",
    "t = 0.0\n",
    "bar = tqdm(total=end_time)\n",
    "\n",
    "timestep = 1e-5\n",
    "t = t0\n",
    "y = y0.copy()\n",
    "step_count = 0\n",
    "start_time = time.time()\n",
    "while t < end_time:\n",
    "\n",
    "    result = integrate_single_step(method, gas, y, t, timestep, rtol, atol, fuel, pressure=pressure, table_id=table_id)\n",
    "    \n",
    "    if not result['success']:\n",
    "        print(f\"Step {step_count} failed: {result['message']}\")\n",
    "        break   \n",
    "    # Update state\n",
    "    y = result['y']\n",
    "    t = result['t']\n",
    "    cpu_times.append(result['cpu_time'])\n",
    "    step_count += 1\n",
    "    fuel_mass_fractions.append(result['fuel_mass_fraction'])\n",
    "\n",
    "    # ensure that y is not empt\n",
    "    if len(y) == 0:\n",
    "        print(f\"Step {step_count} failed: y is empty\")\n",
    "        print(result)\n",
    "        print(y)\n",
    "        break\n",
    "    \n",
    "    # Record data\n",
    "    times.append(t)\n",
    "    temperatures.append(y[0])\n",
    "    for spec in species_to_track:\n",
    "        species_profiles[spec].append(y[gas.species_index(spec) + 1])\n",
    "    \n",
    "    #print(f\"Step {step_count} at time {t:.2e} - temperature {y[0]:.1f}K - CPU time {cpu_times[-1]:.2e}s - time taken {time.time() - start_time:.2f}s | {np.sum(cpu_times):.2e}s\")\n",
    "    bar.set_postfix({\n",
    "        'step': f\"{step_count}\",\n",
    "        'temperature': f\"{y[0]:.1f}K\",\n",
    "        'cpu_time': f\"{cpu_times[-1]:.2e}s\",\n",
    "        'total_cpu_time': f\"{np.sum(cpu_times):.2e}s\"\n",
    "    })\n",
    "bar.close() \n",
    "total_wall_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f43cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 10), dpi=200)\n",
    "ax1.plot(times, temperatures)\n",
    "ax2.plot(times, cpu_times)\n",
    "# plot a vertical line at t = 1e-2\n",
    "ax1.axvline(1e-2, color='red', linestyle='--')\n",
    "ax2.axvline(1e-2, color='red', linestyle='--')\n",
    "\n",
    "# plot the bar chart of the sum of cpu_times, before and after 1e-2\n",
    "ax3.bar(['Before 1e-2', 'After 1e-2'], [np.sum(cpu_times[:10000]), np.sum(cpu_times[10000:])])\n",
    "# write the sum of cpu_times in the bar chart\n",
    "ax3.text(0, np.sum(cpu_times[:10000]), f\"{np.sum(cpu_times[:10000]):.2e}\", ha='center', va='bottom')\n",
    "ax3.text(1, np.sum(cpu_times[10000:]), f\"{np.sum(cpu_times[10000:]):.2e}\", ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dfb580",
   "metadata": {},
   "outputs": [],
   "source": [
    "rk_result = {\n",
    "        'method': method,\n",
    "        'phi': gas.equivalence_ratio,\n",
    "        'rtol': rtol,\n",
    "        'atol': atol,   \n",
    "        'times': np.array(times),\n",
    "        'fuel_mass_fractions': np.array(fuel_mass_fractions),\n",
    "        'temperatures': np.array(temperatures),\n",
    "        'species_profiles': species_profiles,\n",
    "        'cpu_times': np.array(cpu_times),\n",
    "        'total_cpu_time': np.sum(cpu_times),\n",
    "        'total_wall_time': total_wall_time,\n",
    "        'steps': step_count,\n",
    "        'success': step_count > 0,\n",
    "        'timed_out': total_wall_time > time_limit\n",
    "    }\n",
    "\n",
    "\n",
    "error_comparison_rk = calculate_rmse(reference_results, rk_result, ['temperature', 'h', 'h2', 'o', 'o2', 'h2o', 'ho2', 'h2o2', 'oh'], use_log=False)\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 20), dpi=200)\n",
    "\n",
    "for i, specie_name in enumerate(error_comparison_rk.keys()):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    ax.plot(reference_results['times'], np.maximum(error_comparison_rk[specie_name], 1e-10), label='RK23')\n",
    "    # ax.plot(rk_result['times'], np.maximum(error_comparison_bdf[specie_name], 1e-10), label='BDF')\n",
    "    # ax.plot(results['times'], np.maximum(error_comparison_erk[specie_name], 1e-10), label='ERK')\n",
    "    ax.set_title(f\"{specie_name} RMSE\")\n",
    "    ax.legend()\n",
    "    \n",
    "fig.suptitle('Rk23 (1e-6, 1e-8) - BDF (1e-12, 1e-10)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaee80d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_average_forward(array, window_size):\n",
    "    \"\"\"\n",
    "    Calculate running average where each point uses the window starting from that point.\n",
    "    Returns array of same length as input.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    array : array-like\n",
    "        Input array\n",
    "    window_size : int\n",
    "        Size of the averaging window\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Running average array of same length as input\n",
    "    \"\"\"\n",
    "    array = np.array(array)\n",
    "    n = len(array)\n",
    "    result = np.zeros(n)\n",
    "    \n",
    "    # Calculate number of complete windows\n",
    "    num_windows = (n + window_size - 1) // window_size\n",
    "    \n",
    "    # Process each window\n",
    "    for w in range(num_windows):\n",
    "        start_idx = w * window_size\n",
    "        end_idx = min((w + 1) * window_size, n)\n",
    "        window_mean = np.mean(array[start_idx:end_idx])\n",
    "        \n",
    "        # Fill result array for all points that use this window\n",
    "        result[start_idx:end_idx] = window_mean\n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c26637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c03ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7746921",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rtol_tolerances = [1e-12, 1e-11, 1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
    "atol_tolerances = [1e-10, 1e-9, 1e-8, 1e-7, 1e-6]\n",
    "all_tol_data = {} \n",
    "for rtol in rtol_tolerances:\n",
    "    for atol in atol_tolerances:\n",
    "        try:\n",
    "            with open(f'tolerance_analysis_results_rk/tolerance_results_rtol_{rtol}_atol_{atol}.pkl', 'rb') as f:\n",
    "                tolerance_results = pickle.load(f)\n",
    "            all_tol_data[(rtol, atol)] = tolerance_results\n",
    "        except FileNotFoundError:\n",
    "            print(f'File not found for tolerance {rtol} {atol}')\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c180ad1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e982a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_times = rk_bdf_result['cpu_times']\n",
    "temperatures = rk_bdf_result['temperatures']\n",
    "print(f\"Length of times: {len(cpu_times)}\")\n",
    "print(f\"Length of temperatures: {len(temperatures)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc13920",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10), dpi=200)\n",
    "times = reference_results['times']\n",
    "ax1.plot(times, temperatures, label='rk23-bdf (rtol=1e-6, atol=1e-8)')\n",
    "ax1.plot(times, reference_results['temperatures'], label='cvode_bdf (rtol=1e-12, atol=1e-10)', linestyle='--')\n",
    "ax2.plot(times[1:], running_average_forward(cpu_times, 1000), label='rk23-bdf (rtol=1e-8, atol=1e-6)')\n",
    "ax2.plot(times[1:], running_average_forward(reference_results['cpu_times'], 1000), label='cvode_bdf (rtol=1e-12, atol=1e-10)', linestyle='--')\n",
    "\n",
    "time_array = reference_results['times']\n",
    "ax1.axvspan(time_array[0], time_array[pre_end], alpha=0.3, color='green',  \n",
    "            label='Pre-ignition')\n",
    "ax1.axvspan(time_array[ign_start], time_array[ign_end], alpha=0.3, color='red',\n",
    "            label='Ignition')\n",
    "ax1.axvspan(time_array[ign_end], time_array[-1], alpha=0.3, color='blue', \n",
    "            label='Post-ignition')\n",
    "\n",
    "time_array = reference_results['times']\n",
    "ax2.axvspan(time_array[0], time_array[pre_end], alpha=0.3, color='green', \n",
    "            label='Pre-ignition')\n",
    "ax2.axvspan(time_array[ign_start], time_array[ign_end], alpha=0.3, color='red', \n",
    "            label='Ignition')\n",
    "ax2.axvspan(time_array[ign_end], time_array[-1], alpha=0.3, color='blue', \n",
    "            label='Post-ignition')\n",
    "\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634607aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rk_result = all_tol_data[(1e-10, 1e-10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cce064",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_comparison_rk_bdf = calculate_rmse(reference_results, rk_bdf_result, ['temperature', 'h', 'h2', 'o', 'o2', 'h2o', 'ho2', 'h2o2', 'oh'], use_log=False)\n",
    "# error_comparison_bdf = calculate_rmse(reference_results, rk_result, ['temperature', 'h', 'h2', 'o', 'o2', 'h2o', 'ho2', 'h2o2', 'oh'], use_log=False)\n",
    "# error_comparison_erk = calculate_rmse(reference_results, results, ['temperature', 'h', 'h2', 'o', 'o2', 'h2o', 'ho2', 'h2o2', 'oh'], use_log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97646b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_comparison_bdf['h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec24d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "error_comparison_rk_bdf = calculate_rmse(reference_results, rk_bdf_result, ['temperature', 'h', 'h2', 'o', 'o2', 'h2o', 'ho2', 'h2o2', 'oh'], use_log=False)\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 20), dpi=200)\n",
    "\n",
    "for i, specie_name in enumerate(error_comparison_rk_bdf.keys()):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    ax.plot(reference_results['times'], np.maximum(error_comparison_rk_bdf[specie_name], 1e-10), label='RK23-BDF')\n",
    "    # ax.plot(rk_result['times'], np.maximum(error_comparison_bdf[specie_name], 1e-10), label='BDF')\n",
    "    # ax.plot(results['times'], np.maximum(error_comparison_erk[specie_name], 1e-10), label='ERK')\n",
    "    ax.set_title(f\"{specie_name} RMSE\")\n",
    "    ax.legend()\n",
    "    \n",
    "fig.suptitle('Rk23 (1e-6, 1e-8) - BDF (1e-12, 1e-10)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dab666",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 20), dpi=200)\n",
    "\n",
    "for i, specie_name in enumerate(error_comparison_rk_bdf.keys()):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    ax.plot(reference_results['times'], np.log10(np.maximum(error_comparison_rk_bdf[specie_name], 1e-10)), label='RK23-BDF')\n",
    "    # ax.plot(rk_result['times'], np.log10(np.maximum(error_comparison_bdf[specie_name], 1e-10)), label='BDF')\n",
    "    # ax.plot(results['times'], np.log10(np.maximum(error_comparison_erk[specie_name], 1e-10)), label='ERK')\n",
    "    ax.set_title(f\"{specie_name} Log RMSE\")\n",
    "    ax.legend()\n",
    "# add a figure title\n",
    "fig.suptitle('Rk23 (1e-6, 1e-8) - BDF (1e-12, 1e-10)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e5c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerances = [1e-14, 1e-13, 1e-12, 1e-11, 1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
    "tolerance_results = {}\n",
    "\n",
    "for tolerance in tolerances:\n",
    "    gas = ct.Solution(mechanism_file)\n",
    "    \n",
    "    gas.TPX = 1000, sample[1], sample[4:]\n",
    "    y0 = get_initial_state(gas)\n",
    "    tolerance_results[tolerance] = run_integration_experiment(\n",
    "        method, gas, y0, t0, end_time, timestep,\n",
    "        tolerance, tolerance, species_to_track,\n",
    "        fuel, pressure=gas.P,\n",
    "        time_limit=time_limit\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8547219",
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerances = [1e-12, 1e-11, 1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d3e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tolerance_results = {}\n",
    "\n",
    "for tolerance in tolerances:\n",
    "    gas = ct.Solution(mechanism_file)\n",
    "    gas.TPX = 1000, sample[1], sample[4:]\n",
    "    tolerance_results[tolerance] = run_integration_experiment(\n",
    "        method, gas, y0, t0, end_time, timestep,\n",
    "        tolerance, tolerance, species_to_track,\n",
    "        fuel, pressure=gas.P,\n",
    "        time_limit=time_limit\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999221b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "tol_data = pd.read_pickle('tolerance_results2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6596ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tol_2_analyze = \"rtol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774a3c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerances = [1e-12, 1e-11, 1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
    "all_tol_data = {}\n",
    "for tolerance in tolerances:\n",
    "    try:\n",
    "        with open(f'tolerance_study_results/tolerance_results_{tolerance}.pkl', 'rb') as f:\n",
    "            tolerance_results = pickle.load(f)\n",
    "        all_tol_data[tolerance] = tolerance_results\n",
    "    except FileNotFoundError:\n",
    "        print(f'File not found for tolerance {tolerance}')\n",
    "        all_tol_data[tolerance] = tol_data[tolerance]\n",
    "\n",
    "all_tol_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f6a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "line_types = ['-', '--', '-.', ':', '-.', '--', '-', ':', '-.', '--', '-', ':']\n",
    "line_styles = ['solid', 'dashed', 'dashdot', 'dotted', 'solid', 'dashed', 'dashdot', 'dotted', 'solid', 'dashed', 'dashdot', 'dotted']\n",
    "\n",
    "for i, tolerance in enumerate(tolerances):\n",
    "    if all_tol_data[tolerance] is not None:\n",
    "        ax.plot(all_tol_data[tolerance]['times'], all_tol_data[tolerance]['temperatures'], label=f'{tol_2_analyze} {tolerance}', linestyle=line_styles[i], linewidth=2)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf0e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "line_types = ['-', '--', '-.', ':', '-.', '--', '-', ':', '-.', '--', '-', ':']\n",
    "line_styles = ['solid', 'dashed', 'dashdot', 'dotted', 'solid', 'dashed', 'dashdot', 'dotted', 'solid', 'dashed', 'dashdot', 'dotted']\n",
    "\n",
    "for i, tolerance in enumerate(tolerances):\n",
    "    if tolerance in [0.0001, 0.001, 0.01, 0.1]:\n",
    "        pass\n",
    "    else:\n",
    "        if all_tol_data[tolerance] is not None:\n",
    "            ax.plot(all_tol_data[tolerance]['times'][1:], np.log10(all_tol_data[tolerance]['cpu_times']), label=f'{tol_2_analyze} {tolerance}', linestyle=line_styles[i], linewidth=2)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e73996",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "line_types = ['-', '--', '-.', ':', '-.', '--', '-', ':', '-.', '--', '-', ':']\n",
    "line_styles = ['solid', 'dashed', 'dashdot', 'dotted', 'solid', 'dashed', 'dashdot', 'dotted', 'solid', 'dashed', 'dashdot', 'dotted']\n",
    "\n",
    "for i, tolerance in enumerate(tolerances):\n",
    "    if tolerance in [0.0001, 0.001, 0.01, 0.1]:\n",
    "        pass\n",
    "    else:\n",
    "        print(tolerance)\n",
    "        if all_tol_data[tolerance] is not None:\n",
    "            # Calculate running average of CPU times\n",
    "            running_avg = np.cumsum(all_tol_data[tolerance]['cpu_times']) / np.arange(1, len(all_tol_data[tolerance]['cpu_times']) + 1)\n",
    "            \n",
    "            # Plot running average on log scale\n",
    "            ax.plot(all_tol_data[tolerance]['times'][1:], \n",
    "                   running_avg,\n",
    "                   label=f'{tol_2_analyze} {tolerance}',\n",
    "                   linestyle=line_styles[i], \n",
    "                   linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('log10(Running Average CPU Time)')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17634839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def compare_tolerance_effectiveness(all_tol_data, reference_tolerance=1e-14, metrics=['temperature', 'species', 'cpu_time']):\n",
    "    \"\"\"\n",
    "    Compare different tolerance values against a reference tolerance.\n",
    "    \n",
    "    Args:\n",
    "        all_tol_data: Dictionary containing tolerance results for different tolerance values\n",
    "        reference_tolerance: The reference tolerance to compare against (default: 1e-14)\n",
    "        metrics: List of metrics to compare ('temperature', 'species', 'cpu_time')\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing comparison results for each metric\n",
    "    \"\"\"\n",
    "    \n",
    "    if reference_tolerance not in all_tol_data:\n",
    "        print(f\"Reference tolerance {reference_tolerance} not found in data\")\n",
    "        return None\n",
    "    \n",
    "    ref_data = all_tol_data[reference_tolerance]\n",
    "    comparison_results = {}\n",
    "    \n",
    "    # Get available tolerances (excluding reference)\n",
    "    test_tolerances = [tol for tol in all_tol_data.keys() if tol not in [reference_tolerance, 0.0001, 0.001, 0.01, 0.1]]\n",
    "    test_tolerances.sort()\n",
    "    \n",
    "    print(f\"Comparing {len(test_tolerances)} tolerance values against reference {reference_tolerance}\")\n",
    "    print(f\"Available test tolerances: {test_tolerances}\")\n",
    "    \n",
    "    for metric in metrics:\n",
    "        comparison_results[metric] = {}\n",
    "        \n",
    "        if metric == 'temperature':\n",
    "            comparison_results[metric] = compare_temperature_profiles(all_tol_data, reference_tolerance, test_tolerances)\n",
    "        \n",
    "        elif metric == 'species':\n",
    "            comparison_results[metric] = compare_species_profiles(all_tol_data, reference_tolerance, test_tolerances)\n",
    "        \n",
    "        elif metric == 'cpu_time':\n",
    "            comparison_results[metric] = compare_cpu_times(all_tol_data, reference_tolerance, test_tolerances)\n",
    "    \n",
    "    return comparison_results\n",
    "\n",
    "def compare_temperature_profiles(all_tol_data, reference_tolerance, test_tolerances):\n",
    "    \"\"\"Compare temperature profiles between reference and test tolerances.\"\"\"\n",
    "    ref_data = all_tol_data[reference_tolerance]\n",
    "    ref_times = ref_data['times']\n",
    "    ref_temps = ref_data['temperatures']\n",
    "    \n",
    "    temp_comparison = {}\n",
    "    \n",
    "    for tol in test_tolerances:\n",
    "        if all_tol_data[tol] is None:\n",
    "            temp_comparison[tol] = {'error': np.nan, 'max_error': np.nan, 'rmse': np.nan, 'relative_error': np.nan}\n",
    "            continue\n",
    "            \n",
    "        test_data = all_tol_data[tol]\n",
    "        test_times = test_data['times']\n",
    "        test_temps = test_data['temperatures']\n",
    "        \n",
    "        # Interpolate reference data to test time points for comparison\n",
    "        if len(ref_times) > 1 and len(test_times) > 1:\n",
    "            ref_interp = interp1d(ref_times, ref_temps, bounds_error=False, fill_value='extrapolate')\n",
    "            ref_temps_interp = ref_interp(test_times)\n",
    "            \n",
    "            # Calculate errors\n",
    "            errors = test_temps - ref_temps_interp\n",
    "            max_error = np.max(np.abs(errors))\n",
    "            rmse = np.sqrt(np.mean(errors**2))\n",
    "            \n",
    "            # Calculate relative error (avoid division by zero)\n",
    "            ref_temps_safe = np.where(np.abs(ref_temps_interp) > 1e-10, ref_temps_interp, 1e-10)\n",
    "            relative_errors = np.abs(errors) / np.abs(ref_temps_safe)\n",
    "            max_relative_error = np.max(relative_errors)\n",
    "            \n",
    "            temp_comparison[tol] = {\n",
    "                'error': errors,\n",
    "                'max_error': max_error,\n",
    "                'rmse': rmse,\n",
    "                'relative_error': relative_errors,\n",
    "                'max_relative_error': max_relative_error\n",
    "            }\n",
    "        else:\n",
    "            temp_comparison[tol] = {'error': np.nan, 'max_error': np.nan, 'rmse': np.nan, 'relative_error': np.nan}\n",
    "    \n",
    "    return temp_comparison\n",
    "\n",
    "def compare_species_profiles(all_tol_data, reference_tolerance, test_tolerances):\n",
    "    \"\"\"Compare species profiles between reference and test tolerances.\"\"\"\n",
    "    ref_data = all_tol_data[reference_tolerance]\n",
    "    ref_times = ref_data['times']\n",
    "    ref_species = ref_data['species_profiles']\n",
    "    \n",
    "    species_comparison = {}\n",
    "    \n",
    "    for tol in test_tolerances:\n",
    "        if all_tol_data[tol] is None:\n",
    "            species_comparison[tol] = {}\n",
    "            continue\n",
    "            \n",
    "        test_data = all_tol_data[tol]\n",
    "        test_times = test_data['times']\n",
    "        test_species = test_data['species_profiles']\n",
    "        \n",
    "        species_comparison[tol] = {}\n",
    "        \n",
    "        # Compare each species\n",
    "        for species_name in ref_species.keys():\n",
    "            if species_name in test_species:\n",
    "                ref_profile = ref_species[species_name]\n",
    "                test_profile = test_species[species_name]\n",
    "                \n",
    "                # Interpolate reference data to test time points\n",
    "                if len(ref_times) > 1 and len(test_times) > 1:\n",
    "                    ref_interp = interp1d(ref_times, ref_profile, bounds_error=False, fill_value='extrapolate')\n",
    "                    ref_profile_interp = ref_interp(test_times)\n",
    "                    \n",
    "                    # Calculate errors\n",
    "                    errors = test_profile - ref_profile_interp\n",
    "                    max_error = np.max(np.abs(errors))\n",
    "                    rmse = np.sqrt(np.mean(errors**2))\n",
    "                    \n",
    "                    # Calculate relative error\n",
    "                    ref_profile_safe = np.where(np.abs(ref_profile_interp) > 1e-10, ref_profile_interp, 1e-10)\n",
    "                    relative_errors = np.abs(errors) / np.abs(ref_profile_safe)\n",
    "                    max_relative_error = np.max(relative_errors)\n",
    "                    \n",
    "                    species_comparison[tol][species_name] = {\n",
    "                        'error': errors,\n",
    "                        'max_error': max_error,\n",
    "                        'rmse': rmse,\n",
    "                        'relative_error': relative_errors,\n",
    "                        'max_relative_error': max_relative_error\n",
    "                    }\n",
    "                else:\n",
    "                    species_comparison[tol][species_name] = {\n",
    "                        'error': np.nan, 'max_error': np.nan, 'rmse': np.nan, \n",
    "                        'relative_error': np.nan, 'max_relative_error': np.nan\n",
    "                    }\n",
    "    \n",
    "    return species_comparison\n",
    "\n",
    "def compare_cpu_times(all_tol_data, reference_tolerance, test_tolerances):\n",
    "    \"\"\"Compare CPU times between reference and test tolerances.\"\"\"\n",
    "    ref_data = all_tol_data[reference_tolerance]\n",
    "    ref_cpu_time = ref_data['total_cpu_time']\n",
    "    \n",
    "    cpu_comparison = {}\n",
    "    \n",
    "    for tol in test_tolerances:\n",
    "        if all_tol_data[tol] is None:\n",
    "            cpu_comparison[tol] = {'cpu_time': np.nan, 'speedup': np.nan, 'efficiency': np.nan}\n",
    "            continue\n",
    "            \n",
    "        test_data = all_tol_data[tol]\n",
    "        test_cpu_time = test_data['total_cpu_time']\n",
    "        \n",
    "        # Calculate speedup and efficiency\n",
    "        speedup = ref_cpu_time / test_cpu_time if test_cpu_time > 0 else np.nan\n",
    "        efficiency = speedup if speedup <= 1 else 1/speedup\n",
    "        \n",
    "        cpu_comparison[tol] = {\n",
    "            'cpu_time': test_cpu_time,\n",
    "            'speedup': speedup,\n",
    "            'efficiency': efficiency\n",
    "        }\n",
    "    \n",
    "    return cpu_comparison\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Compare all tolerances against the most precise one (1e-14)\n",
    "comparison_results = compare_tolerance_effectiveness(\n",
    "    all_tol_data, \n",
    "    reference_tolerance=1e-12, \n",
    "    metrics=['temperature', 'species', 'cpu_time']\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fdf686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save comparison results to a pickle file\n",
    "with open('comparison_results_rtol.pkl', 'wb') as f:\n",
    "    pickle.dump(comparison_results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab9a03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load comparison results from a pickle file\n",
    "with open('comparison_results_rtol.pkl', 'rb') as f:\n",
    "    comparison_results_rtol = pickle.load(f)\n",
    "\n",
    "with open('comparison_results_atol.pkl', 'rb') as f:\n",
    "    comparison_results_atol = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232b1cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/elotech/Downloads/research_code/tolerance_study_results_/tolerance_results_1e-12.pkl', 'rb') as f:\n",
    "    single_result = pickle.load(f)\n",
    "\n",
    "single_result.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec68952",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_cpu_time = np.sum(single_result['cpu_times'])\n",
    "\n",
    "\n",
    "print(f\"Single CPU time: {single_cpu_time}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcdb07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_results_rtol['cpu_time'][1e-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdebaf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_results_atol['cpu_time'][1e-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c4a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "136.78664755821228 - 128.32024765014648"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e4196",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE\n",
    "RTOL - 1e-12, ATOL - 1e-10 = 0.06409171894867949\n",
    "ATOL - 1e-12, RTOL - 1e-10 = 0.11352238592234361"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b11453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tolerance_comparison(comparison_results, reference_tolerance=1e-14, tol_2_analyze='atol'):\n",
    "    \"\"\"Plot comparison results for different metrics.\"\"\"\n",
    "    \n",
    "    # Temperature comparison\n",
    "    if 'temperature' in comparison_results:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Plot max absolute error vs tolerance\n",
    "        tolerances = list(comparison_results['temperature'].keys())\n",
    "        # Plot error profiles over time for each tolerance\n",
    "        for tol in tolerances:\n",
    "            if 'error' in comparison_results['temperature'][tol]:\n",
    "                times = np.arange(len(comparison_results['temperature'][tol]['error'])) * 1e-6\n",
    "                errors = comparison_results['temperature'][tol]['error']\n",
    "                axes[0, 0].plot(times, np.log10(np.maximum(errors, 1e-10)), '-', linewidth=2, label=f'{tol_2_analyze}={tol}')\n",
    "        \n",
    "        axes[0, 0].set_xlabel('Time (s)')\n",
    "        axes[0, 0].set_ylabel('Absolute Error (K)')\n",
    "        axes[0, 0].set_title('Temperature Error Profiles')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        axes[0, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        # Plot RMSE vs tolerance\n",
    "        rmses = [comparison_results['temperature'][tol]['rmse'] for tol in tolerances]\n",
    "        axes[0, 1].semilogx(tolerances, rmses, 's-', linewidth=2, markersize=8, color='orange')\n",
    "        axes[0, 1].set_xlabel(f'{tol_2_analyze}')\n",
    "        axes[0, 1].set_ylabel('RMSE (K)')\n",
    "        axes[0, 1].set_title(f'Temperature: RMSE vs {tol_2_analyze}')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot max relative error vs tolerance\n",
    "        max_rel_errors = [comparison_results['temperature'][tol]['max_relative_error'] for tol in tolerances]\n",
    "        axes[1, 0].semilogx(tolerances, max_rel_errors, '^-', linewidth=2, markersize=8, color='green')\n",
    "        axes[1, 0].set_xlabel(f'{tol_2_analyze}')\n",
    "        axes[1, 0].set_ylabel('Max Relative Error')\n",
    "        axes[1, 0].set_title(f'Temperature: Max Relative Error vs {tol_2_analyze}')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # CPU time comparison\n",
    "        if 'cpu_time' in comparison_results:\n",
    "            cpu_times = [comparison_results['cpu_time'][tol]['cpu_time'] for tol in tolerances]\n",
    "            axes[1, 1].semilogx(tolerances, cpu_times, 'd-', linewidth=2, markersize=8, color='red')\n",
    "            axes[1, 1].set_xlabel(f'{tol_2_analyze}')\n",
    "            axes[1, 1].set_ylabel('CPU Time (s)')\n",
    "            axes[1, 1].set_title(f'CPU Time vs {tol_2_analyze}')\n",
    "            axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Species comparison summary\n",
    "    if 'species' in comparison_results:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        tolerances = list(comparison_results['species'].keys())\n",
    "        species_names = list(comparison_results['species'][tolerances[0]].keys()) if tolerances else []\n",
    "        \n",
    "        # Calculate average RMSE across all species for each tolerance\n",
    "        avg_rmses = []\n",
    "        for tol in tolerances:\n",
    "            if comparison_results['species'][tol]:\n",
    "                rmses = [comparison_results['species'][tol][sp]['rmse'] for sp in species_names \n",
    "                        if 'rmse' in comparison_results['species'][tol][sp]]\n",
    "                avg_rmses.append(np.mean(rmses) if rmses else np.nan)\n",
    "            else:\n",
    "                avg_rmses.append(np.nan)\n",
    "        \n",
    "        ax.semilogx(tolerances, avg_rmses, 'o-', linewidth=2, markersize=8, color='purple')\n",
    "        ax.set_xlabel(f'{tol_2_analyze}')\n",
    "        ax.set_ylabel('Average RMSE across all species')\n",
    "        ax.set_title(f'Species Profiles: Average RMSE vs {tol_2_analyze}')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "def print_tolerance_summary(comparison_results, reference_tolerance=1e-14):\n",
    "    \"\"\"Print a summary of tolerance comparison results.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TOLERANCE COMPARISON SUMMARY (Reference: {reference_tolerance})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if 'temperature' in comparison_results:\n",
    "        print(\"\\nTEMPERATURE COMPARISON:\")\n",
    "        print(\"-\" * 40)\n",
    "        for tol in sorted(comparison_results['temperature'].keys()):\n",
    "            result = comparison_results['temperature'][tol]\n",
    "            if not np.isnan(result['max_error']):\n",
    "                print(f\"Tolerance {tol:>8}: Max Error = {result['max_error']:>8.2f} K, \"\n",
    "                      f\"RMSE = {result['rmse']:>8.2f} K, \"\n",
    "                      f\"Max Rel Error = {result['max_relative_error']:>8.2e}\")\n",
    "    \n",
    "    if 'cpu_time' in comparison_results:\n",
    "        print(\"\\nCPU TIME COMPARISON:\")\n",
    "        print(\"-\" * 40)\n",
    "        for tol in sorted(comparison_results['cpu_time'].keys()):\n",
    "            result = comparison_results['cpu_time'][tol]\n",
    "            if not np.isnan(result['cpu_time']):\n",
    "                print(f\"Tolerance {tol:>8}: CPU Time = {result['cpu_time']:>8.2f} s, \"\n",
    "                      f\"Speedup = {result['speedup']:>8.2f}x\")\n",
    "    \n",
    "    if 'species' in comparison_results:\n",
    "        print(\"\\nSPECIES PROFILES COMPARISON:\")\n",
    "        print(\"-\" * 40)\n",
    "        tolerances = list(comparison_results['species'].keys())\n",
    "        if tolerances:\n",
    "            species_names = list(comparison_results['species'][tolerances[0]].keys())\n",
    "            print(f\"Number of species compared: {len(species_names)}\")\n",
    "            \n",
    "            # Show average RMSE for each tolerance\n",
    "            for tol in sorted(tolerances):\n",
    "                if comparison_results['species'][tol]:\n",
    "                    rmses = [comparison_results['species'][tol][sp]['rmse'] for sp in species_names \n",
    "                            if 'rmse' in comparison_results['species'][tol][sp]]\n",
    "                    avg_rmse = np.mean(rmses) if rmses else np.nan\n",
    "                    if not np.isnan(avg_rmse):\n",
    "                        print(f\"Tolerance {tol:>8}: Average RMSE = {avg_rmse:>8.2e}\")\n",
    "# Print summary\n",
    "if comparison_results:\n",
    "    # print_tolerance_summary(comparison_results, reference_tolerance=1e-14)\n",
    "    \n",
    "    # Plot results\n",
    "    plot_tolerance_comparison(comparison_results, reference_tolerance=1e-14, tol_2_analyze=tol_2_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8ba661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_consecutive_tolerances(all_tol_data, available_tolerance=None, metrics=['temperature', 'species', 'cpu_time']):\n",
    "    \"\"\"\n",
    "    Compare consecutive tolerance values in a cascading manner.\n",
    "    \n",
    "    This function compares each tolerance with the next less precise one:\n",
    "    - 1e-13 vs 1e-14 (reference)\n",
    "    - 1e-12 vs 1e-13 (reference)\n",
    "    - 1e-11 vs 1e-12 (reference)\n",
    "    - ... and so on\n",
    "    \n",
    "    Args:\n",
    "        all_tol_data: Dictionary containing tolerance results\n",
    "        metrics: List of metrics to compare ('temperature', 'species', 'cpu_time')\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing cascading comparison results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get available tolerances and sort them from most precise to least precise\n",
    "    if available_tolerance is None:\n",
    "        available_tolerances = [tol for tol in all_tol_data.keys() if all_tol_data[tol] is not None]\n",
    "    else:\n",
    "        # Filter out tolerances that don't exist in all_tol_data\n",
    "        available_tolerances = [tol for tol in available_tolerance if tol in all_tol_data and all_tol_data[tol] is not None]\n",
    "\n",
    "    available_tolerances.sort()  # Sort from smallest to largest (most precise to least precise)\n",
    "    \n",
    "    if len(available_tolerances) < 2:\n",
    "        print(\"Need at least 2 tolerance values for comparison\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Performing cascading tolerance comparison for {len(available_tolerances)} tolerance values\")\n",
    "    print(f\"Tolerance order (most precise to least precise): {available_tolerances}\")\n",
    "    \n",
    "    cascading_results = {}\n",
    "    \n",
    "    for metric in metrics:\n",
    "        cascading_results[metric] = {}\n",
    "        \n",
    "        if metric == 'temperature':\n",
    "            cascading_results[metric] = compare_consecutive_temperature_profiles(all_tol_data, available_tolerances)\n",
    "        \n",
    "        elif metric == 'species':\n",
    "            cascading_results[metric] = compare_consecutive_species_profiles(all_tol_data, available_tolerances)\n",
    "        \n",
    "        elif metric == 'cpu_time':\n",
    "            cascading_results[metric] = compare_consecutive_cpu_times(all_tol_data, available_tolerances)\n",
    "    \n",
    "    return cascading_results\n",
    "\n",
    "def compare_consecutive_temperature_profiles(all_tol_data, available_tolerances):\n",
    "    \"\"\"Compare temperature profiles between consecutive tolerance values.\"\"\"\n",
    "    \n",
    "    temp_comparison = {}\n",
    "    previous_max_error = None  # Track previous max error for growth factor calculation\n",
    "    \n",
    "    # Compare each tolerance with the next less precise one\n",
    "    for i in range(len(available_tolerances) - 1):\n",
    "        current_tol = available_tolerances[i]      # More precise (reference)\n",
    "        next_tol = available_tolerances[i + 1]    # Less precise (test)\n",
    "        \n",
    "        print(f\"Comparing {next_tol} vs {current_tol} (reference)\")\n",
    "        \n",
    "        current_data = all_tol_data[current_tol]\n",
    "        next_data = all_tol_data[next_tol]\n",
    "        \n",
    "        current_times = current_data['times']\n",
    "        current_temps = current_data['temperatures']\n",
    "        next_times = next_data['times']\n",
    "        next_temps = next_data['temperatures']\n",
    "        \n",
    "        # Interpolate reference data to test tolerance time points\n",
    "        if len(next_times) > 1 and len(current_times) > 1:\n",
    "            current_interp = interp1d(current_times, current_temps, bounds_error=False, fill_value='extrapolate')\n",
    "            current_temps_interp = current_interp(next_times)\n",
    "            \n",
    "            # Calculate errors\n",
    "            errors = next_temps - current_temps_interp\n",
    "            max_error = np.max(np.abs(errors))\n",
    "            rmse = np.sqrt(np.mean(errors**2))\n",
    "            \n",
    "            # Calculate relative error (avoid division by zero)\n",
    "            current_temps_safe = np.where(np.abs(current_temps_interp) > 1e-10, current_temps_interp, 1e-10)\n",
    "            relative_errors = np.abs(errors) / np.abs(current_temps_safe)\n",
    "            max_relative_error = np.max(relative_errors)\n",
    "            \n",
    "            # Calculate error growth factor (how much error increases from one tolerance to the next)\n",
    "            if i == 0:  # First comparison, no previous error to compare\n",
    "                error_growth_factor = 1.0  # Set to 1 for the first comparison\n",
    "            else:\n",
    "                error_growth_factor = max_error / previous_max_error if previous_max_error > 0 else np.nan\n",
    "            \n",
    "            temp_comparison[next_tol] = {\n",
    "                'reference_tolerance': current_tol,\n",
    "                'error': errors,\n",
    "                'max_error': max_error,\n",
    "                'rmse': rmse,\n",
    "                'relative_error': relative_errors,\n",
    "                'max_relative_error': max_relative_error,\n",
    "                'error_growth_factor': error_growth_factor\n",
    "            }\n",
    "            \n",
    "            # Update previous_max_error for next iteration\n",
    "            previous_max_error = max_error\n",
    "            \n",
    "        else:\n",
    "            temp_comparison[next_tol] = {\n",
    "                'reference_tolerance': current_tol,\n",
    "                'error': np.nan, 'max_error': np.nan, 'rmse': np.nan, \n",
    "                'relative_error': np.nan, 'max_relative_error': np.nan,\n",
    "                'error_growth_factor': np.nan\n",
    "            }\n",
    "    \n",
    "    return temp_comparison\n",
    "\n",
    "def compare_consecutive_species_profiles(all_tol_data, available_tolerances):\n",
    "    \"\"\"Compare species profiles between consecutive tolerance values.\"\"\"\n",
    "    \n",
    "    species_comparison = {}\n",
    "    \n",
    "    # Compare each tolerance with the next less precise one\n",
    "    for i in range(len(available_tolerances) - 1):\n",
    "        current_tol = available_tolerances[i]      # More precise (reference)\n",
    "        next_tol = available_tolerances[i + 1]    # Less precise (test)\n",
    "        \n",
    "        current_data = all_tol_data[current_tol]\n",
    "        next_data = all_tol_data[next_tol]\n",
    "        \n",
    "        current_times = current_data['times']\n",
    "        current_species = current_data['species_profiles']\n",
    "        next_times = next_data['times']\n",
    "        next_species = next_data['species_profiles']\n",
    "        \n",
    "        species_comparison[next_tol] = {\n",
    "            'reference_tolerance': current_tol,\n",
    "            'species_errors': {}\n",
    "        }\n",
    "        \n",
    "        # Compare each species\n",
    "        for species_name in next_species.keys():\n",
    "            if species_name in current_species:\n",
    "                current_profile = current_species[species_name]\n",
    "                next_profile = next_species[species_name]\n",
    "                \n",
    "                # Interpolate reference data to test tolerance time points\n",
    "                if len(next_times) > 1 and len(current_times) > 1:\n",
    "                    current_interp = interp1d(current_times, current_profile, bounds_error=False, fill_value='extrapolate')\n",
    "                    current_profile_interp = current_interp(next_times)\n",
    "                    \n",
    "                    # Calculate errors\n",
    "                    errors = next_profile - current_profile_interp\n",
    "                    max_error = np.max(np.abs(errors))\n",
    "                    rmse = np.sqrt(np.mean(errors**2))\n",
    "                    \n",
    "                    # Calculate relative error\n",
    "                    current_profile_safe = np.where(np.abs(current_profile_interp) > 1e-10, current_profile_interp, 1e-10)\n",
    "                    relative_errors = np.abs(errors) / np.abs(current_profile_safe)\n",
    "                    max_relative_error = np.max(relative_errors)\n",
    "                    \n",
    "                    species_comparison[next_tol]['species_errors'][species_name] = {\n",
    "                        'error': errors,\n",
    "                        'max_error': max_error,\n",
    "                        'rmse': rmse,\n",
    "                        'relative_error': relative_errors,\n",
    "                        'max_relative_error': max_relative_error\n",
    "                    }\n",
    "                else:\n",
    "                    species_comparison[next_tol]['species_errors'][species_name] = {\n",
    "                        'error': np.nan, 'max_error': np.nan, 'rmse': np.nan, \n",
    "                        'relative_error': np.nan, 'max_relative_error': np.nan\n",
    "                    }\n",
    "    \n",
    "    return species_comparison\n",
    "\n",
    "def compare_consecutive_cpu_times(all_tol_data, available_tolerances):\n",
    "    \"\"\"Compare CPU times between consecutive tolerance values.\"\"\"\n",
    "    \n",
    "    cpu_comparison = {}\n",
    "    \n",
    "    # Compare each tolerance with the next less precise one\n",
    "    for i in range(len(available_tolerances) - 1):\n",
    "        current_tol = available_tolerances[i]      # More precise (reference)\n",
    "        next_tol = available_tolerances[i + 1]    # Less precise (test)\n",
    "        \n",
    "        current_data = all_tol_data[current_tol]\n",
    "        next_data = all_tol_data[next_tol]\n",
    "        \n",
    "        current_cpu_time = current_data['total_cpu_time']\n",
    "        next_cpu_time = next_data['total_cpu_time']\n",
    "        \n",
    "        # Calculate speedup and efficiency\n",
    "        speedup = current_cpu_time / next_cpu_time if next_cpu_time > 0 else np.nan\n",
    "        efficiency = speedup if speedup <= 1 else 1/speedup\n",
    "        \n",
    "        # Calculate computational cost ratio\n",
    "        cost_ratio = next_cpu_time / current_cpu_time if current_cpu_time > 0 else np.nan\n",
    "        \n",
    "        cpu_comparison[next_tol] = {\n",
    "            'reference_tolerance': current_tol,\n",
    "            'cpu_time': next_cpu_time,\n",
    "            'reference_cpu_time': current_cpu_time,\n",
    "            'speedup': speedup,\n",
    "            'efficiency': efficiency,\n",
    "            'cost_ratio': cost_ratio\n",
    "        }\n",
    "    \n",
    "    return cpu_comparison\n",
    "\n",
    "# Example usage:\n",
    "available_tolerances = [1e-12, 1e-11, 1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
    "cascading_results = compare_consecutive_tolerances(all_tol_data, available_tolerances, metrics=['temperature', 'species', 'cpu_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b98909",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_cascading_comparison(cascading_results, available_tolerances, tol_2_analyze):\n",
    "    \"\"\"Plot results from cascading tolerance comparison.\"\"\"\n",
    "    \n",
    "    if not cascading_results:\n",
    "        print(\"No cascading results to plot\")\n",
    "        return\n",
    "    \n",
    "    # Temperature comparison\n",
    "    if 'temperature' in cascading_results:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Get test tolerances that actually have results\n",
    "        test_tolerances = list(cascading_results['temperature'].keys())\n",
    "        test_tolerances.sort()  # Sort from smallest to largest\n",
    "        \n",
    "        for tol in test_tolerances:\n",
    "            if 'error' in cascading_results['temperature'][tol]:\n",
    "                times = np.arange(len(cascading_results['temperature'][tol]['error'])) * 1e-6\n",
    "                errors = cascading_results['temperature'][tol]['error']\n",
    "                axes[0, 0].plot(times, np.log10(np.maximum(errors, 1e-10)), '-', linewidth=2, label=f'{tol_2_analyze}={tol}')\n",
    "        \n",
    "        axes[0, 0].set_xlabel(f'{tol_2_analyze}')\n",
    "        axes[0, 0].set_ylabel('Max Absolute Error (K)')\n",
    "        axes[0, 0].set_title(f'Temperature: Max Error vs {tol_2_analyze}\\n(Compared to next more precise tolerance)')\n",
    "        axes[0, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot RMSE vs tolerance\n",
    "        rmses = [cascading_results['temperature'][tol]['rmse'] for tol in test_tolerances]\n",
    "        axes[0, 1].semilogx(test_tolerances, rmses, 's-', linewidth=2, markersize=8, color='orange')\n",
    "        axes[0, 1].set_xlabel(f'{tol_2_analyze}')\n",
    "        axes[0, 1].set_ylabel('RMSE (K)')\n",
    "        axes[0, 1].set_title(f'Temperature: RMSE vs {tol_2_analyze}\\n(Compared to next more precise tolerance)')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot max relative error vs tolerance\n",
    "        max_rel_errors = [cascading_results['temperature'][tol]['max_relative_error'] for tol in test_tolerances]\n",
    "        axes[1, 0].semilogx(test_tolerances, max_rel_errors, '^-', linewidth=2, markersize=8, color='green')\n",
    "        axes[1, 0].set_xlabel(f'{tol_2_analyze}')\n",
    "        axes[1, 0].set_ylabel('Max Relative Error')\n",
    "        axes[1, 0].set_title(f'Temperature: Max Relative Error vs {tol_2_analyze}\\n(Compared to next more precise tolerance)')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot error growth factor vs tolerance\n",
    "        error_growth_factors = [cascading_results['temperature'][tol]['error_growth_factor'] for tol in test_tolerances]\n",
    "        axes[1, 1].semilogx(test_tolerances, error_growth_factors, 'd-', linewidth=2, markersize=8, color='red')\n",
    "        axes[1, 1].set_xlabel(f'{tol_2_analyze}')\n",
    "        axes[1, 1].set_ylabel('Error Growth Factor')\n",
    "        axes[1, 1].set_title(f'Temperature: Error Growth Factor vs {tol_2_analyze}\\n(How much error increases from one tolerance to the next)')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Species comparison\n",
    "    if 'species' in cascading_results:\n",
    "        # Get all species names from the first tolerance result\n",
    "        test_tolerances = list(cascading_results['species'].keys())\n",
    "        test_tolerances.sort()  # Sort from smallest to largest\n",
    "        \n",
    "        if test_tolerances:\n",
    "            first_tol = test_tolerances[0]\n",
    "            species_names = list(cascading_results['species'][first_tol]['species_errors'].keys())\n",
    "            \n",
    "            # Determine number of species and create subplot grid\n",
    "            n_species = len(species_names)\n",
    "            if n_species > 0:\n",
    "                # Create a reasonable subplot layout\n",
    "                if n_species <= 4:\n",
    "                    rows, cols = 2, 2\n",
    "                elif n_species <= 6:\n",
    "                    rows, cols = 2, 3\n",
    "                elif n_species <= 9:\n",
    "                    rows, cols = 3, 3\n",
    "                else:\n",
    "                    rows, cols = 4, 4  # For more species, might need scrolling or separate plots\n",
    "                \n",
    "                fig, axes = plt.subplots(rows, cols, figsize=(15, 12))\n",
    "                if rows == 1 and cols == 1:\n",
    "                    axes = [axes]\n",
    "                elif rows == 1 or cols == 1:\n",
    "                    axes = axes.flatten()\n",
    "                else:\n",
    "                    axes = axes.flatten()\n",
    "                \n",
    "                # Plot each species\n",
    "                for i, species_name in enumerate(species_names[:rows*cols]):  # Limit to subplot grid\n",
    "                    ax = axes[i]\n",
    "                    \n",
    "                    # Extract max errors for this species across all tolerances\n",
    "                    max_errors = []\n",
    "                    for tol in test_tolerances:\n",
    "                        if species_name in cascading_results['species'][tol]['species_errors']:\n",
    "                            error = cascading_results['species'][tol]['species_errors'][species_name]['max_error']\n",
    "                            max_errors.append(error)\n",
    "                        else:\n",
    "                            max_errors.append(np.nan)\n",
    "                    \n",
    "                    # Plot on log-log scale (log tolerance vs log error)\n",
    "                    valid_indices = ~np.isnan(max_errors)\n",
    "                    if np.any(valid_indices):\n",
    "                        valid_tolerances = np.array(test_tolerances)[valid_indices]\n",
    "                        valid_errors = np.array(max_errors)[valid_indices]\n",
    "                        \n",
    "                        # Remove zero or negative errors for log scale\n",
    "                        positive_mask = valid_errors > 0\n",
    "                        if np.any(positive_mask):\n",
    "                            ax.loglog(valid_tolerances[positive_mask], valid_errors[positive_mask], \n",
    "                                     'o-', linewidth=2, markersize=6)\n",
    "                    \n",
    "                    ax.set_xlabel(f'{tol_2_analyze}')\n",
    "                    ax.set_ylabel('Max Absolute Error (log scale)')\n",
    "                    ax.set_title(f'{species_name}\\nMax Error vs {tol_2_analyze}')\n",
    "                    ax.grid(True, alpha=0.3)\n",
    "                \n",
    "                # Hide unused subplots\n",
    "                for i in range(len(species_names), rows*cols):\n",
    "                    axes[i].set_visible(False)\n",
    "                \n",
    "                plt.suptitle('Species: Max Error vs Tolerance (Log-Log Scale)\\n(Compared to next more precise tolerance)', \n",
    "                           fontsize=14)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                # Create a second plot for relative errors\n",
    "                fig, axes = plt.subplots(rows, cols, figsize=(15, 12))\n",
    "                if rows == 1 and cols == 1:\n",
    "                    axes = [axes]\n",
    "                elif rows == 1 or cols == 1:\n",
    "                    axes = axes.flatten()\n",
    "                else:\n",
    "                    axes = axes.flatten()\n",
    "                \n",
    "                # Plot relative errors for each species\n",
    "                for i, species_name in enumerate(species_names[:rows*cols]):\n",
    "                    ax = axes[i]\n",
    "                    \n",
    "                    # Extract max relative errors for this species across all tolerances\n",
    "                    max_rel_errors = []\n",
    "                    for tol in test_tolerances:\n",
    "                        if species_name in cascading_results['species'][tol]['species_errors']:\n",
    "                            rel_error = cascading_results['species'][tol]['species_errors'][species_name]['max_relative_error']\n",
    "                            max_rel_errors.append(rel_error)\n",
    "                        else:\n",
    "                            max_rel_errors.append(np.nan)\n",
    "                    \n",
    "                    # Plot on semi-log scale\n",
    "                    valid_indices = ~np.isnan(max_rel_errors)\n",
    "                    if np.any(valid_indices):\n",
    "                        valid_tolerances = np.array(test_tolerances)[valid_indices]\n",
    "                        valid_rel_errors = np.array(max_rel_errors)[valid_indices]\n",
    "                        \n",
    "                        # Remove zero or negative errors for log scale\n",
    "                        positive_mask = valid_rel_errors > 0\n",
    "                        if np.any(positive_mask):\n",
    "                            ax.semilogx(valid_tolerances[positive_mask], valid_rel_errors[positive_mask], \n",
    "                                      's-', linewidth=2, markersize=6, color='orange')\n",
    "                    \n",
    "                    ax.set_xlabel(f'{tol_2_analyze}')\n",
    "                    ax.set_ylabel('Max Relative Error')\n",
    "                    ax.set_title(f'{species_name}\\nMax Relative Error vs {tol_2_analyze}')\n",
    "                    ax.grid(True, alpha=0.3)\n",
    "                \n",
    "                # Hide unused subplots\n",
    "                for i in range(len(species_names), rows*cols):\n",
    "                    axes[i].set_visible(False)\n",
    "                \n",
    "                plt.suptitle(f'Species: Max Relative Error vs {tol_2_analyze}\\n(Compared to next more precise tolerance)', \n",
    "                           fontsize=14)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "    \n",
    "    # CPU time comparison\n",
    "    if 'cpu_time' in cascading_results:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # Get test tolerances that actually have results\n",
    "        test_tolerances = list(cascading_results['cpu_time'].keys())\n",
    "        test_tolerances.sort()  # Sort from smallest to largest\n",
    "        \n",
    "        # Plot speedup vs tolerance\n",
    "        speedups = [cascading_results['cpu_time'][tol]['speedup'] for tol in test_tolerances]\n",
    "        axes[0].semilogx(test_tolerances, speedups, 'o-', linewidth=2, markersize=8, color='blue')\n",
    "        axes[0].set_xlabel(f'{tol_2_analyze}')\n",
    "        axes[0].set_ylabel('Speedup vs Next More Precise Tolerance')\n",
    "        axes[0].set_title(f'Speedup vs {tol_2_analyze}\\n(Compared to next more precise tolerance)')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot cost ratio vs tolerance\n",
    "        cost_ratios = [cascading_results['cpu_time'][tol]['cost_ratio'] for tol in test_tolerances]\n",
    "        axes[1].semilogx(test_tolerances, cost_ratios, 's-', linewidth=2, markersize=8, color='purple')\n",
    "        axes[1].set_xlabel(f'{tol_2_analyze}')\n",
    "        axes[1].set_ylabel('Computational Cost Ratio')\n",
    "        axes[1].set_title(f'Computational Cost Ratio vs {tol_2_analyze}\\n(Compared to next more precise tolerance)')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def print_cascading_summary(cascading_results, available_tolerances):\n",
    "    \"\"\"Print a summary of cascading tolerance comparison results.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CASCADING TOLERANCE COMPARISON SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Tolerance order (most precise to least precise): {available_tolerances}\")\n",
    "    print(f\"Number of comparisons: {len(available_tolerances) - 1}\")\n",
    "    \n",
    "    if 'temperature' in cascading_results:\n",
    "        print(f\"\\n{'TEMPERATURE CASCADING COMPARISON':-^80}\")\n",
    "        print(f\"{'Tolerance':>12} {'Reference':>12} {'Max Error':>12} {'RMSE':>12} {'Max Rel Error':>15}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Get the actual tolerances that have comparison results\n",
    "        test_tolerances = list(cascading_results['temperature'].keys())\n",
    "        # Sort them to match the tolerance order\n",
    "        test_tolerances.sort(reverse=True)  # Most precise to least precise\n",
    "        \n",
    "        for tol in test_tolerances:\n",
    "            result = cascading_results['temperature'][tol]\n",
    "            if not np.isnan(result['max_error']):\n",
    "                print(f\"{tol:>12} {result['reference_tolerance']:>12} \"\n",
    "                      f\"{result['max_error']:>12.2f} {result['rmse']:>12.2f} \"\n",
    "                      f\"{result['max_relative_error']:>15.2e}\")\n",
    "    \n",
    "    if 'cpu_time' in cascading_results:\n",
    "        print(f\"\\n{'CPU TIME CASCADING COMPARISON':-^80}\")\n",
    "        print(f\"{'Tolerance':>12} {'Reference':>12} {'CPU Time':>12} {'Speedup':>12} {'Cost Ratio':>12}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Get the actual tolerances that have comparison results\n",
    "        test_tolerances = list(cascading_results['cpu_time'].keys())\n",
    "        # Sort them to match the tolerance order\n",
    "        test_tolerances.sort(reverse=True)  # Most precise to least precise\n",
    "        \n",
    "        for tol in test_tolerances:\n",
    "            result = cascading_results['cpu_time'][tol]\n",
    "            if not np.isnan(result['cpu_time']):\n",
    "                print(f\"{tol:>12} {result['reference_tolerance']:>12} \"\n",
    "                      f\"{result['cpu_time']:>12.2f} {result['speedup']:>12.2f} \"\n",
    "                      f\"{result['cost_ratio']:>12.2f}\")\n",
    "    \n",
    "    # Analyze error propagation\n",
    "    if 'temperature' in cascading_results:\n",
    "        print(f\"\\n{'ERROR PROPAGATION ANALYSIS':-^80}\")\n",
    "        \n",
    "        # Get the actual tolerances that have comparison results\n",
    "        test_tolerances = list(cascading_results['temperature'].keys())\n",
    "        test_tolerances.sort(reverse=True)  # Most precise to least precise\n",
    "        error_growth_factors = []\n",
    "        \n",
    "        for tol in test_tolerances:\n",
    "            result = cascading_results['temperature'][tol]\n",
    "            if not np.isnan(result['error_growth_factor']):\n",
    "                error_growth_factors.append(result['error_growth_factor'])\n",
    "        \n",
    "        if error_growth_factors:\n",
    "            avg_growth = np.mean(error_growth_factors)\n",
    "            max_growth = np.max(error_growth_factors)\n",
    "            min_growth = np.min(error_growth_factors)\n",
    "            \n",
    "            print(f\"Average error growth factor: {avg_growth:.2f}\")\n",
    "            print(f\"Maximum error growth factor: {max_growth:.2f}\")\n",
    "            print(f\"Minimum error growth factor: {min_growth:.2f}\")\n",
    "            \n",
    "            if avg_growth > 1.5:\n",
    "                print(\"  Warning: High error propagation detected - errors are growing significantly between tolerance levels\")\n",
    "            elif avg_growth < 1.1:\n",
    "                print(\" Good: Low error propagation - errors are growing slowly between tolerance levels\")\n",
    "            else:\n",
    "                print(\"  Moderate: Some error propagation - errors are growing moderately between tolerance levels\")\n",
    "\n",
    "\n",
    "# print_cascading_summary(cascading_results, available_tolerances)\n",
    "plot_cascading_comparison(cascading_results, available_tolerances, tol_2_analyze=tol_2_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130b41f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtol_tolerances = [1e-12, 1e-11, 1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
    "atol_tolerances = [1e-10, 1e-9, 1e-8, 1e-7, 1e-6]\n",
    "all_tol_data = {} \n",
    "for rtol in rtol_tolerances:\n",
    "    for atol in atol_tolerances:\n",
    "        try:\n",
    "            with open(f'tolerance_analysis_results/tolerance_results_rtol_{rtol}_atol_{atol}.pkl', 'rb') as f:\n",
    "                tolerance_results = pickle.load(f)\n",
    "            all_tol_data[(rtol, atol)] = tolerance_results\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "\n",
    "all_tol_data.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
